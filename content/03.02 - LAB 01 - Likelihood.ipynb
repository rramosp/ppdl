{"cells": [{"cell_type": "code", "execution_count": null, "id": "2e244b03", "metadata": {}, "outputs": [], "source": ["# init repo notebook\n", "!git clone https://github.com/rramosp/ppdl.git > /dev/null 2> /dev/null\n", "!mv -n ppdl/content/init.py ppdl/content/local . 2> /dev/null\n", "!pip install -r ppdl/content/requirements.txt > /dev/null"]}, {"cell_type": "markdown", "id": "2dee74c4", "metadata": {}, "source": ["# Lab 03.02.01\n", "\n", "In this laboratory we'll understand the **likelihood** concept, its uses and limitations."]}, {"cell_type": "code", "execution_count": null, "id": "c01eb35f", "metadata": {}, "outputs": [], "source": ["## Ignore this cell\n", "!pip install ppdl==0.1.5 rlxmoocapi==0.1.0 --quiet"]}, {"cell_type": "code", "execution_count": null, "id": "731a6eaa", "metadata": {}, "outputs": [], "source": ["course_id = \"ppdl.v1\"\n", "endpoint = \"https://m5knaekxo6.execute-api.us-west-2.amazonaws.com/dev-v0001/rlxmooc\"\n", "lab = \"L02.02.01\""]}, {"cell_type": "code", "execution_count": null, "id": "1729529e", "metadata": {}, "outputs": [], "source": ["import inspect\n", "from rlxmoocapi import submit, session\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from functools import partial\n", "from sklearn.datasets import make_blobs\n", "from scipy.optimize import minimize\n", "plt.style.use(\"ggplot\")"]}, {"cell_type": "markdown", "id": "9dbf5c7b", "metadata": {}, "source": ["Log-in with your username and password:"]}, {"cell_type": "code", "execution_count": null, "id": "55e11996", "metadata": {}, "outputs": [], "source": ["session.LoginSequence(\n", "    endpoint=endpoint,\n", "    course_id=course_id,\n", "    lab_id=lab,\n", "    varname=\"student\"\n", "    );"]}, {"cell_type": "markdown", "id": "9e48add3", "metadata": {}, "source": ["In this case, we'll be using the following synthetic dataset:"]}, {"cell_type": "code", "execution_count": null, "id": "60ad5e05", "metadata": {}, "outputs": [], "source": ["X, y = make_blobs(\n", "        n_samples=500,\n", "        n_features=2,\n", "        centers=2,\n", "        random_state=42\n", "        )"]}, {"cell_type": "code", "execution_count": null, "id": "8032664b", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["fig, ax = plt.subplots(figsize=(10, 10))\n", "ax.scatter(X[:, 0], X[:, 1], c=y)\n", "ax.set_xlabel(\"$x_1$\")\n", "ax.set_ylabel(\"$x_2$\")"]}, {"cell_type": "markdown", "id": "4ca9040c", "metadata": {}, "source": ["## Task 1\n", "\n", "Implement the output probability distribution for a logistic regression model, this model is intended to work over features in $\\mathbb{R}^2$, i.e., the model's parameters are the vector $\\mathbf{w} = [w_1, w_2]$ and the bias $b$.\n", "\n", "You must parameterize $\\mathbf{w}$ in a polar coordinate system, and consider the radians $\\mathbf{\\theta}$ only, not the vector's magnitude.\n", "\n", "$$\n", "P(y_i=1|\\mathbf{x_i};\\mathbf{w}, b) = \\frac{1}{1 + e^{\\mathbf{x_i}\\cdot\\mathbf{w} + b}}\n", "$$\n", "\n", "You must implement something similar to:\n", "\n", "$$\n", "P(y_i=1|\\mathbf{x_i};\\theta, \\mathbf{b}) = \\frac{1}{1 + e^{\\mathbf{x_i} \\cdot \\vec{f}(\\theta) + b}}\n", "$$\n", "\n", "Where $\\theta \\in [0, 2 \\pi]$, $b \\in \\mathbb{R}$ and $\\vec{f}: \\mathbb{R} \\rightarrow \\mathbb{R}^2$ is a function that generates an unitary vector given an angle in radians $\\theta$:"]}, {"cell_type": "code", "execution_count": null, "id": "23365182", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["def radian_logistic(X, theta, b):\n", "    ..."]}, {"cell_type": "markdown", "id": "4051b1b5", "metadata": {}, "source": ["Your function must return the same output when you run the next cell.\n", "\n", "![radian logistic](local/imgs/radian_logistic.png)"]}, {"cell_type": "code", "execution_count": null, "id": "049721f5", "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(3, 5, figsize=(10, 7))\n", "theta = np.linspace(0, np.pi, 5)\n", "b = np.array([-1, 0, 1])\n", "\n", "x_grid = np.linspace(-1, 1, 100)\n", "X1, X2 = np.meshgrid(x_grid, x_grid)\n", "X_grid = np.concatenate([X1.reshape(-1, 1), X2.reshape(-1, 1)], axis=1)\n", "\n", "for i in range(5):\n", "    for j in range(3):\n", "        probs = radian_logistic(X_grid, theta[i], b[j])\n", "        axi = ax[j, i]\n", "        axi.contourf(X1, X2, probs.reshape(X1.shape), alpha=0.5)\n", "        axi.set_xlabel(\"$x_1$\")\n", "        axi.set_ylabel(\"$x_2$\")\n", "        axi.set_title(f\"$\\\\theta={theta[i]:.2f}$, $b={b[j]}$\")\n", "fig.tight_layout()"]}, {"cell_type": "code", "execution_count": null, "id": "ebcaf171", "metadata": {}, "outputs": [], "source": ["student.submit_task(namespace=globals(), task_id=\"T1\");"]}, {"cell_type": "markdown", "id": "300dd175", "metadata": {}, "source": ["## Task 2\n", "\n", "Implement the log-likelihood function for the model, where $D=(\\mathbf{X}, \\mathbf{y})$\n", "\n", "$$\n", "\\mathcal{L}(\\theta, b) = \\text{log} P(D; \\theta, b)\\\\\n", "\\mathcal{L}(\\theta, b) = \\text{log}\\prod_{i=1}^N P(y_i|\\mathcal{x_i};\\theta, b)\n", "$$"]}, {"cell_type": "code", "execution_count": null, "id": "3c5a4234", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["def log_likelihood(X, y, params):\n", "    theta, b = params\n", "    ..."]}, {"cell_type": "markdown", "id": "dea8335f", "metadata": {}, "source": ["Let us explore the likelihood function for different $(\\theta, b)$ values, the following code cell must generate the following output:\n", "\n", "![Log-likelihood](local/imgs/radian_logistic_loglik.png)"]}, {"cell_type": "code", "execution_count": null, "id": "7dee91dd", "metadata": {}, "outputs": [], "source": ["theta = np.linspace(0, 2 * np.pi, 20)\n", "b = np.zeros((1, 2))\n", "\n", "b = np.linspace(-20, 20, 20)\n", "T, B = np.meshgrid(theta, b)\n", "params_grid = np.concatenate([T.reshape(-1, 1), B.reshape(-1, 1)], axis=1)\n", "lik_fun = partial(log_likelihood, X=X, y=y)\n", "\n", "lik = np.array([lik_fun(params=params_i) for params_i in params_grid])\n", "\n", "fig, ax = plt.subplots(figsize=(7, 7))\n", "im = ax.contourf(T, B, lik.reshape(T.shape), alpha=0.5)\n", "ax.set_xlabel(r\"$\\theta$\")\n", "ax.set_ylabel(\"$b$\")\n", "ax.set_title(\"Log-likelihood\")\n", "fig.colorbar(im)"]}, {"cell_type": "markdown", "id": "f49c0080", "metadata": {}, "source": ["We can also view the likelihood:\n", "\n", "![likelihood](local/imgs/radian_logistic_lik.png)"]}, {"cell_type": "code", "execution_count": null, "id": "5575e7bb", "metadata": {}, "outputs": [], "source": ["theta = np.linspace(0, 2 * np.pi, 20)\n", "b = np.zeros((1, 2))\n", "\n", "b = np.linspace(-20, 20, 20)\n", "T, B = np.meshgrid(theta, b)\n", "params_grid = np.concatenate([T.reshape(-1, 1), B.reshape(-1, 1)], axis=1)\n", "lik_fun = partial(log_likelihood, X=X, y=y)\n", "\n", "lik = np.array([lik_fun(params=params_i) for params_i in params_grid])\n", "\n", "fig, ax = plt.subplots(figsize=(7, 7))\n", "im = ax.contourf(T, B, np.exp(lik.reshape(T.shape)), alpha=0.5)\n", "ax.set_xlabel(r\"$\\theta$\")\n", "ax.set_ylabel(\"$b$\")\n", "ax.set_title(\"Likelihood\")\n", "fig.colorbar(im)"]}, {"cell_type": "markdown", "id": "e8fbbd90", "metadata": {}, "source": ["Let's do a deep-dive into this joint likelihood function's parameters:\n", "\n", "1. $\\theta$ has a periodic behavior, which is reasonable considering the periodicity that occurs in a polar coordinate system.\n", "2. The values in $b$ are more likely around 0 (related with the features' range).\n", "\n", "Let's see the best parameters according to maximum likelihood estimation"]}, {"cell_type": "code", "execution_count": null, "id": "872ea430", "metadata": {}, "outputs": [], "source": ["params = minimize(\n", "        lambda params: -log_likelihood(X, y, params),\n", "        x0=np.zeros((2, ))\n", "        )\n", "theta_sol, b_sol = params.x[0], params.x[1]\n", "print(theta_sol)\n", "print(b_sol)"]}, {"cell_type": "markdown", "id": "436f7348", "metadata": {}, "source": ["Finally, let's see the predictions with this parameters. Your solution must look like:\n", "\n", "![predictions](local/imgs/radian_logistic_preds.png)"]}, {"cell_type": "code", "execution_count": null, "id": "4cfe924a", "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(figsize=(10, 7))\n", "x1 = np.linspace(X[:, 0].min(), X[:, 0].max(), 100)\n", "x2 = np.linspace(X[:, 1].min(), X[:, 1].max(), 100)\n", "X1, X2 = np.meshgrid(x1, x2)\n", "X_grid = np.concatenate([X1.reshape(-1, 1), X2.reshape(-1, 1)], axis=1)\n", "y_pred = radian_logistic(X_grid, theta_sol, b_sol)\n", "\n", "ax.contourf(X1, X2, y_pred.reshape(X1.shape), alpha=0.5)\n", "ax.scatter(X[:, 0], X[:, 1], c=y)\n", "ax.set_xlabel(r\"$\\theta$\")\n", "ax.set_ylabel(\"$b$\")"]}, {"cell_type": "code", "execution_count": null, "id": "49297dcd", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["student.submit_task(namespace=globals(), task_id=\"T2\");"]}, {"cell_type": "markdown", "id": "a70bf996", "metadata": {}, "source": ["## Task 3\n", "\n", "In this case, We're going to assume that the likelihood is equal to the joint distribution of the model $P(D, \\theta, b)$ (which is wrong), and we're going to marginalize over the parameters to assert if We've a valid probability distribution.\n", "\n", "You must implement the following operation:\n", "\n", "$$\n", "\\int_{\\theta}\\int_{b}P(D, \\theta, b) db ~ d\\theta\n", "$$\n", "\n", "Using a discrete approximation:\n", "\n", "$$\n", "\\sum_{\\theta} \\sum_{b} \\text{exp}(\\mathcal{L}(\\theta, b)) \\Delta_{\\theta} \\Delta_{b}\\\\\n", "\\sum_{i} \\sum_{j} \\text{exp}(\\mathcal{L}(\\theta_i, b_j)) (\\theta_{i+1} - \\theta_{i}) (b_{j+1} - b_j)\n", "$$"]}, {"cell_type": "code", "execution_count": null, "id": "49a85d26", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["def integral(X, y, min_theta, max_theta, min_b, max_b, n_points):\n", "    theta_range = np.linspace(min_theta, max_theta, n_points)\n", "    b_range = np.linspace(min_b, max_b, n_points)\n", "    delta_theta = theta_range[1] - theta_range[0]\n", "    delta_b = b_range[1] - b_range[0]\n", "    volumes = (\n", "            (\n", "                np.exp(log_likelihood(\n", "                    X, y, np.array([theta_range[i], b_range[j]])\n", "                    )) * \n", "                delta_theta * delta_b\n", "                )\n", "            for i in range(theta_range.size - 1)\n", "            for j in range(b_range.size - 1)\n", "            )\n", "    return sum(volumes)"]}, {"cell_type": "code", "execution_count": null, "id": "f9dee8ca", "metadata": {}, "outputs": [], "source": ["min_theta, max_theta = 0, 2 * np.pi\n", "min_b, max_b = -20, 20\n", "n_points = 100\n", "\n", "print(integral(X, y, min_theta, max_theta, min_b, max_b, n_points))"]}, {"cell_type": "code", "execution_count": null, "id": "e5e11f14", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["student.submit_task(namespace=globals(), task_id=\"T3\");"]}, {"cell_type": "markdown", "id": "c7f86c81", "metadata": {}, "source": ["## Task 4\n", "\n", "In this task you must compute the probibility of observing the evidence $P(D)$ using a bayesian approach, to this end, We'll assume the following prior distributions for the parameters:\n", "\n", "$$\n", "\\theta \\sim U(1, 4)\\\\\n", "b \\sim U(-10, 5)\n", "$$\n", "\n", "You must compute:\n", "\n", "$$\n", "P(D) = \\int_{\\theta} \\int_{b} P(D|\\theta, b)P(\\theta)P(b)db ~ d\\theta\\\\\n", "P(D) = \\int_{\\theta} \\int_{b} \\text{exp}(L(\\theta, b))P(\\theta)P(b)db ~ d\\theta\n", "$$\n", "\n", "Using a numerical approximation:\n", "\n", "$$\n", "\\sum_{i} \\sum_{j} \\text{exp}(\\mathcal{L}(\\theta_i, b_j)) P(\\theta)P(b) (\\theta_{i+1} - \\theta_{i}) (b_{j+1} - b_j)\n", "$$"]}, {"cell_type": "code", "execution_count": null, "id": "0dcc410a", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["def evidence(X, y, min_theta, max_theta, min_b, max_b, n_points):\n", "    theta_range = np.linspace(min_theta, max_theta, n_points)\n", "    b_range = np.linspace(min_b, max_b, n_points)\n", "    delta_theta = theta_range[1] - theta_range[0]\n", "    delta_b = b_range[1] - b_range[0]\n", "    volumes = (\n", "            (\n", "                np.exp(log_likelihood(\n", "                    X, y, np.array([theta_range[i], b_range[j]])\n", "                    )) * \n", "                (1 / (max_theta - min_theta)) *\n", "                (1 / (max_b - min_b)) *\n", "                delta_theta * delta_b\n", "                )\n", "            for i in range(theta_range.size - 1)\n", "            for j in range(b_range.size - 1)\n", "            )\n", "    return sum(volumes)"]}, {"cell_type": "code", "execution_count": null, "id": "2dce722c", "metadata": {}, "outputs": [], "source": ["min_theta, max_theta = 1, 4\n", "min_b, max_b = -10, 5\n", "n_points = 100\n", "\n", "print(evidence(X, y, min_theta, max_theta, min_b, max_b, n_points))"]}, {"cell_type": "markdown", "id": "d42eef82", "metadata": {}, "source": ["Your result must be equal to `4.613945937156545e-05`.\n", "\n", "def grader4(functions, variables, caller_userid):\n", "    import numpy as np\n", "\n", "    namespace = locals()\n", "    for f in functions.values():\n", "        exec(f, namespace)\n", "\n", "    def evidence_sol(X, y, min_theta, max_theta, min_b, max_b, n_points):\n", "        theta_range = np.linspace(min_theta, max_theta, n_points)\n", "        b_range = np.linspace(min_b, max_b, n_points)\n", "        delta_theta = theta_range[1] - theta_range[0]\n", "        delta_b = b_range[1] - b_range[0]\n", "        volumes = (\n", "                (\n", "                    np.exp(log_likelihood(\n", "                        X, y, np.array([theta_range[i], b_range[j]])\n", "                        )) * \n", "                    (1 / (max_theta - min_theta)) *\n", "                    (1 / (max_b - min_b)) *\n", "                    delta_theta * delta_b\n", "                    )\n", "                for i in range(theta_range.size - 1)\n", "                for j in range(b_range.size - 1)\n", "                )\n", "        return sum(volumes)\n", "\n", "    radian_logistic = namespace[\"radian_logistic\"]\n", "    log_likelihood = namespace[\"log_likelihood\"]\n", "    evidence = namespace[\"evidence\"]\n", "\n", "    msg = \"Testing your code with 10 randomly generated cases </br>\"\n", "\n", "    for _ in range(10):\n", "        n_features = 2\n", "        n_samples = np.random.randint(10, 100)\n", "        X = np.random.uniform(size=(n_samples, n_features))\n", "        y = np.random.randint(0, 2, size=(n_samples))\n", "        min_theta = np.random.uniform(0, np.pi)\n", "        max_theta = np.random.uniform(np.pi, 2 * np.pi)\n", "        min_b = np.random.uniform(-10, 0)\n", "        max_b = np.random.uniform(0, 10)\n", "        n_points = np.random.randint(5, 20)\n", "\n", "        evidence_res = evidence(X, y, min_theta, max_theta, min_b, max_b, n_points)\n", "        if not isinstance(evidence_res, float):\n", "            msg += f\"<b>Your function must return a float number, it's returning a {type(evidence_res)}</b></br>\"\n", "            return 0, msg\n", "\n", "        evidence_res_sol = evidence_sol(X, y, min_theta, max_theta, min_b, max_b, n_points)\n", "\n", "        if not np.isclose(evidence_res_sol, evidence_res):\n", "            msg += f\"<b>Wrong answer!</b></br>\"\n", "            return 0, msg\n", "\n", "    return 5, msg + \"<b>Success!</b>\""]}, {"cell_type": "code", "execution_count": null, "id": "0d66b69a", "metadata": {}, "outputs": [], "source": ["student.submit_task(namespace=globals(), task_id=\"T4\");"]}], "metadata": {"jupytext": {"cell_metadata_filter": "-all", "main_language": "python", "notebook_metadata_filter": "-all"}}, "nbformat": 4, "nbformat_minor": 5}