
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>a normal distribution, parametrized by \(\mu=a\) &#8212; Probabilistic Programming for Machine Learning</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/xglobal.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/spectre.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/spectre-exp.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/spectre-icons.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-MBFEZ3PF64"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-MBFEZ3PF64');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/logo-tf-udea-unal.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Probabilistic Programming for Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../intro.html">
   Welcome
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../outline.html">
   Course outline
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../M1-videolist.html">
   1 Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../M2-videolist.html">
   2 TF for Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../M3-videolist.html">
   3 Intuitions on Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../M4-videolist.html">
   4 Tensorflow Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../M5-videolist.html">
   5 Bayesian Modelling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../M6-videolist.html">
   6 Variational Inference
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/content/04.02 - Variational inference/research/minimizing expectation.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/rramosp/ppdl/blob/main/content/04.02 - Variational inference/research/minimizing expectation.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../../../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   a normal distribution, parametrized by
   <span class="math notranslate nohighlight">
    \(\mu=a\)
   </span>
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#check-and-inspect-the-probability-distribution">
   check and inspect the probability distribution
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-function">
   a function
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fix-a-and-comparing-eq-1-and-eq-2">
   fix
   <span class="math notranslate nohighlight">
    \(a\)
   </span>
   and comparing eq (1) and eq (2)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#observe-the-reparametrization-trick">
     observe  the reparametrization trick
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#let-s-do-a-small-gradient-ascent-to-get-the-best-a">
   let’s do a small gradient ascent to get the best
   <span class="math notranslate nohighlight">
    \(a\)
   </span>
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>a normal distribution, parametrized by \mu=a</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   a normal distribution, parametrized by
   <span class="math notranslate nohighlight">
    \(\mu=a\)
   </span>
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#check-and-inspect-the-probability-distribution">
   check and inspect the probability distribution
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-function">
   a function
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fix-a-and-comparing-eq-1-and-eq-2">
   fix
   <span class="math notranslate nohighlight">
    \(a\)
   </span>
   and comparing eq (1) and eq (2)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#observe-the-reparametrization-trick">
     observe  the reparametrization trick
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#let-s-do-a-small-gradient-ascent-to-get-the-best-a">
   let’s do a small gradient ascent to get the best
   <span class="math notranslate nohighlight">
    \(a\)
   </span>
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import sympy as sy
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
from scipy.integrate import quad
from progressbar import progressbar as pbar
from rlxutils import subplots
import pandas as pd
%matplotlib inline
</pre></div>
</div>
</div>
</div>
<p>from</p>
<ul class="simple">
<li><p>https://stats.stackexchange.com/questions/199605/how-does-the-reparameterization-trick-for-vaes-work-and-why-is-it-important</p></li>
<li><p>https://ermongroup.github.io/cs228-notes/</p></li>
</ul>
<p>observe that we can rewrite the gradient of a function in the following manner:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\nabla_\theta q(x) &amp;= \frac{q(x)}{q(x)}\nabla_\theta q(x)\\
&amp;=q(x)\nabla_\theta \log q(x)
\end{align}
\end{split}\]</div>
<p>This is nice, because if <strong><span class="math notranslate nohighlight">\(q(x)\)</span> is a probability distribution</strong> and we need to integrate <span class="math notranslate nohighlight">\(\int \nabla_\theta q(x)\)</span>, we can:</p>
<ul class="simple">
<li><p>rewrite it as <span class="math notranslate nohighlight">\(\int q(x) \nabla_\theta \log q(x)\)</span></p></li>
<li><p>use a MC estimate <span class="math notranslate nohighlight">\(\frac{1}{N}\sum_{x_i \sim q} \nabla_\theta \log q(x_i)\)</span></p></li>
</ul>
<p><strong>In particular</strong>, if we are computing the <strong>gradient of an expectation</strong> of a function <span class="math notranslate nohighlight">\(f(x)\)</span> with respect to distribution <span class="math notranslate nohighlight">\(q(x)\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\nabla_\theta \mathbb{E}_q[f(x)] &amp;= \nabla_\theta \int q(x) f(x) dx &amp;\;\;\;\;(1)\\
&amp;= \int \nabla_\theta \big[q(x) f(x) \big] dx \\
&amp;= \int  \big[ f(x)\nabla_\theta q(x) + q(x)\nabla_\theta f(x) \big] dx \\
&amp;= \int  \big[ f(x)q(x)\nabla_\theta \log q(x) + q(x)\nabla_\theta f(x) \big] dx \\
&amp;= \int  q(x) \big[ f(x)\nabla_\theta \log q(x) + \nabla_\theta f(x) \big] dx \\
&amp;= \mathbb{E}_q  \big[ f(x)\nabla_\theta \log q(x) + \nabla_\theta f(x) \big] \\
&amp;\approx \frac{1}{N}\sum_{x_i \sim q}  \big[ f(x_i)\nabla_\theta \log q(x_i) + \nabla_\theta f(x_i) \big]  &amp;\;\;\;\;(2)\\
\end{align}
\end{split}\]</div>
<p>eq (1) is the analytical expression for the expectation and eq (2) is its Montecarlo estimation</p>
<div class="section" id="a-normal-distribution-parametrized-by-mu-a">
<h1>a normal distribution, parametrized by <span class="math notranslate nohighlight">\(\mu=a\)</span><a class="headerlink" href="#a-normal-distribution-parametrized-by-mu-a" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(a \in [-5, 5]\)</span></p></li>
</ul>
<div class="math notranslate nohighlight">
\[x \sim \mathcal{N}(a, 1)\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>x, a, px = sy.symbols(r&quot;x a p_x&quot;)

amin, amax = -5,5

sigma = sy.N(1)
# the PDF
#pdf  = sy.exp(-0.5*((x-a)/sigma_val)**2)/(sigma_val*sy.sqrt(2*sy.pi))
pdfx  = sy.exp(-0.5*((x-a)/sigma)**2)/(sigma*sy.sqrt(2*sy.pi))

_pdfx = sy.lambdify([x, a], pdfx, &quot;numpy&quot;)

# a random value for parameter a
random_a = lambda N=1: np.random.random(N)*(amax-amin) + amin

# sampling from the distribution
samplex = lambda a_val, N: stats.norm(loc=a_val, scale=float(sigma.subs({a: a_val}))).rvs(N)

samplee = lambda N: stats.norm(loc=0, scale=1).rvs(N)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def get_xmin_xmax(a_val):
    _x = np.linspace(-1000,1000,1000000)
    _x = _x[_pdfx(_x, a=a_val)&gt;1e-10]
    return _x.min(), _x.max()
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="check-and-inspect-the-probability-distribution">
<h1>check and inspect the probability distribution<a class="headerlink" href="#check-and-inspect-the-probability-distribution" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for ax, i in subplots(2, usizex=6, usizey=4):
    if i==0:
        a_val = random_a()[0]
        xmin, xmax = get_xmin_xmax(a_val)
        x_range = np.linspace(xmin,xmax,100)
        plt.plot(x_range, _pdfx(x_range, a_val), color=&quot;black&quot;, label=&quot;PDF&quot;)
        N = 100000
        xs = samplex(a_val, N)
        plt.hist(xs, bins=100, density=True, alpha=.5, color=&quot;orange&quot;, label=&quot;samples&quot;);
        plt.grid();
        plt.xlabel(&quot;x&quot;)
        plt.ylabel(&quot;$q_a(x)$&quot;)
        plt.title(f&quot;a={a_val:.3f}    checking PDF\n  {N} samples (using CDF and inv CDF)&quot;);
        plt.legend();
    if i==1:
        a_range = np.linspace(amin, amax, 100)
        int01 = [quad(lambda x: _pdfx(x, a_val), *get_xmin_xmax(a_val))[0] for a_val in a_range]
        plt.plot(a_range, int01)
        plt.xlabel(&quot;a&quot;)
        plt.grid();
        plt.title(&quot;value of $\int_0^1 q_a(x) dx$&quot;)
        plt.ylim(.9,1.1)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/minimizing expectation_9_0.png" src="../../../_images/minimizing expectation_9_0.png" />
</div>
</div>
</div>
<div class="section" id="a-function">
<h1>a function<a class="headerlink" href="#a-function" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>f = sy.sin(x)
#f = sy.sin((a-np.pi/20)**2*x**2)
f = a*sy.sin(-a**2)*x
#f = sy.sin(x)*(x-1)**2
#f = sy.N(1)
f = sy.sin(a)**2 + (x-2)**2
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="fix-a-and-comparing-eq-1-and-eq-2">
<h1>fix <span class="math notranslate nohighlight">\(a\)</span> and comparing eq (1) and eq (2)<a class="headerlink" href="#fix-a-and-comparing-eq-1-and-eq-2" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def compute_gradient_analytical(a_val):
    eint_fn = sy.lambdify(x, (pdfx*f).diff(a).subs({a: a_val}), &quot;numpy&quot;)
    
    return quad(eint_fn, *get_xmin_xmax(a_val))[0]

def compute_gradient_mc(a_val, N=1000):
    qs = samplex(a_val, N)
    grad_fn = sy.lambdify(x, (f.diff(a) + sy.log(pdfx).diff(a)*f).subs({a: a_val}), &quot;numpy&quot;)
    return grad_fn(qs).mean()

def compute_expectation_analytical(a_val):
    eint_fn = sy.lambdify(x, (pdfx*f).subs({a: a_val}), &quot;numpy&quot;)
    return quad(eint_fn, *get_xmin_xmax(a_val))[0]

def compute_expectation_mc(a_val, N=1000):
    qs = samplex(a_val, N)
    grad_fn = sy.lambdify(x, f.subs({a: a_val}), &quot;numpy&quot;)
    return grad_fn(qs).mean()
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>## using the reparametrization trick

def compute_egradient_mc(a_val, N=1000):
    es = samplee(N)
    
    e = sy.symbols(&quot;\epsilon&quot;)
    fdiff = f.subs({x: a+e}).diff(a).subs({a: a_val})
    return sy.lambdify(e, fdiff, &quot;numpy&quot;)(es).mean()


def compute_eexpectation_mc(a_val, N=1000):
    es = samplee(N)    
    e = sy.symbols(&quot;\epsilon&quot;)
    eint = f.subs({x: a+e}).subs({a: a_val})    
    exp_fn = sy.lambdify(e, eint, &quot;numpy&quot;)
    return exp_fn(es).mean()
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>compute_expectation_mc(2, N=1000000), compute_eexpectation_mc(2, N=1000000)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1.8280966355339079, 1.8275915583355455)
</pre></div>
</div>
</div>
</div>
<div class="section" id="observe-the-reparametrization-trick">
<h2>observe  the reparametrization trick<a class="headerlink" href="#observe-the-reparametrization-trick" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>we have more stability when we estimate the gradient of the expectation with the reparametrization trick</p></li>
<li><p>same stability when estimating the expectation</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>a_range = np.linspace(amin, amax, 100)
N = 10
ge_analitical = [compute_gradient_analytical(a_val) for a_val in a_range]
ge_mc  = [compute_gradient_mc(a_val, N=N) for a_val in a_range]
ege_mc = [compute_egradient_mc(a_val, N=N) for a_val in a_range]

e_analitical = [compute_expectation_analytical(a_val) for a_val in a_range]
e_mc = [compute_expectation_mc(a_val, N=N) for a_val in a_range]
ee_mc = [compute_eexpectation_mc(a_val, N=N) for a_val in a_range]

a_best = a_range[np.argmin(np.r_[ge_analitical]**2)]

for ax, i in subplots(2, usizex=6, usizey=5):
    if i==0:
        plt.plot(a_range, ge_analitical, label=&quot;analytical&quot;, lw=5, color=&quot;red&quot;, alpha=.5)
        plt.plot(a_range, ge_mc, label=f&quot;mc with N={N}&quot;, color=&quot;orange&quot;)
        plt.plot(a_range, ege_mc, label=f&quot;mc_trick with N={N}&quot;, color=&quot;black&quot;)
        plt.grid();
        plt.title(r&quot;gradient of the expectation $\rightarrow$  $\nabla_a \mathbb{E} f_a(x)$&quot;)
        plt.xlabel(&quot;a&quot;)
        plt.axvline(a_best, color=&quot;black&quot;, label=f&quot;best $a$ = {a_best: .3f}&quot;, ls=&quot;--&quot;)
        plt.legend(loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
        plt.legend(loc=&#39;upper center&#39;, ncol=2, bbox_to_anchor=(0.5, -0.2))        
    if i==1:
        plt.plot(a_range, e_analitical, label=&quot;analytical&quot;, lw=5, color=&quot;red&quot;, alpha=.5)
        plt.plot(a_range, e_mc, label=f&quot;montecarlo with N={N}&quot;, color=&quot;orange&quot;)
        plt.plot(a_range, ee_mc, label=f&quot;mc_trick with N={N}&quot;, color=&quot;black&quot;)
        plt.grid();
        plt.axvline(a_best, color=&quot;black&quot;, label=f&quot;best $a$ = {a_best: .3f}&quot;, ls=&quot;--&quot;)
        plt.title(r&quot;expectation $\rightarrow$  $\mathbb{E} f_a(x)$&quot;)
        plt.xlabel(&quot;a&quot;)
        plt.legend(loc=&#39;upper center&#39;, ncol=2, bbox_to_anchor=(0.5, -0.2))     
        
plt.tight_layout()

</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/minimizing expectation_17_0.png" src="../../../_images/minimizing expectation_17_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="let-s-do-a-small-gradient-ascent-to-get-the-best-a">
<h1>let’s do a small gradient ascent to get the best <span class="math notranslate nohighlight">\(a\)</span><a class="headerlink" href="#let-s-do-a-small-gradient-ascent-to-get-the-best-a" title="Permalink to this headline">¶</a></h1>
<div class="math notranslate nohighlight">
\[\text{arg min}_a \; \mathbb{E}_q[f(x)]\]</div>
<ul class="simple">
<li><p>we only use MC estimates for the gradient</p></li>
<li><p>observe that when we use the reparametrization trick everything is more stable <strong>specially with small <span class="math notranslate nohighlight">\(N\)</span></strong> (&lt;3)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>

def optimize(N=1, use_reparametrization_trick=True, init_a_val=None):

    if init_a_val is None:
        a_val = np.random.random()*(amax-amin) + amin
    else:
        a_val = init_a_val
        
    learning_rate = .1
    lr_decay = 1e-2
    h = []
    
    print (&quot;initial a&quot;, a_val)
    
    for step in range(101):

        if use_reparametrization_trick:
            grad = compute_egradient_mc(a_val, N)
        else:
            grad = compute_gradient_mc(a_val, N)
        expectation = compute_expectation_mc(a_val, N)

        if step%10==0:
            print (f&quot;step {step:2d}: expectation for a={a_val:.3f} is {expectation:.5f}, grad is {grad:.5f}, lr is {learning_rate:.5f}&quot;)

        a_val -= learning_rate * grad
        learning_rate *= (1-lr_decay)
        h.append([step, a_val, expectation, grad, learning_rate])

    h = pd.DataFrame(h, columns=[&#39;step&#39;, &#39;a&#39;, &#39;expectation&#39;, &#39;grad&#39;, &#39;lr&#39;])
    
    return h
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>init_a_val = np.random.random()*(amax-amin) + amin
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>h_trick = optimize(use_reparametrization_trick=True, N=2, init_a_val=init_a_val)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>initial a -1.7770103976630702
step  0: expectation for a=-1.777 is 19.78645, grad is -5.96232, lr is 0.10000
step 10: expectation for a=1.304 is 1.13101, grad is -0.34098, lr is 0.09044
step 20: expectation for a=2.355 is 0.68706, grad is -0.34821, lr is 0.08179
step 30: expectation for a=2.620 is 0.47441, grad is 3.36597, lr is 0.07397
step 40: expectation for a=2.503 is 0.57136, grad is 1.38405, lr is 0.06690
step 50: expectation for a=2.566 is 1.13726, grad is -1.46419, lr is 0.06050
step 60: expectation for a=2.422 is 0.64909, grad is 0.54236, lr is 0.05472
step 70: expectation for a=2.572 is 0.31104, grad is -0.72392, lr is 0.04948
step 80: expectation for a=2.345 is 1.38757, grad is -1.26029, lr is 0.04475
step 90: expectation for a=2.696 is 2.23243, grad is -0.54363, lr is 0.04047
step 100: expectation for a=2.524 is 0.67570, grad is -0.37034, lr is 0.03660
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>h_notrick = optimize(use_reparametrization_trick=False, N=2, init_a_val=init_a_val)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>initial a -1.7770103976630702
step  0: expectation for a=-1.777 is 21.99800, grad is 5.32794, lr is 0.10000
step 10: expectation for a=1.346 is 4.39296, grad is 3.20461, lr is 0.09044
step 20: expectation for a=0.570 is 1.21199, grad is 1.24163, lr is 0.08179
step 30: expectation for a=0.253 is 5.02888, grad is 1.26900, lr is 0.07397
step 40: expectation for a=1.803 is 3.12637, grad is -0.20225, lr is 0.06690
step 50: expectation for a=3.162 is 2.27290, grad is -0.19006, lr is 0.06050
step 60: expectation for a=2.520 is 0.51382, grad is -1.06490, lr is 0.05472
step 70: expectation for a=2.696 is 3.61985, grad is -0.88434, lr is 0.04948
step 80: expectation for a=2.489 is 0.52850, grad is -1.86870, lr is 0.04475
step 90: expectation for a=2.254 is 1.42146, grad is -2.49970, lr is 0.04047
step 100: expectation for a=2.638 is 0.34662, grad is -2.84563, lr is 0.03660
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for ax,i in subplots(3, usizex=5):
    if i==0:
        plt.plot(h_trick.grad.values, label=&quot;with rep trick&quot;)
        plt.plot(h_notrick.grad.values, label=&quot;no trick&quot;)
        plt.grid(); plt.legend(); plt.xlabel(&quot;step&quot;); plt.title(&quot;gradient&quot;);
    if i==1:
        plt.plot(h_trick.a.values, label=&quot;with rep trick&quot;)
        plt.plot(h_notrick.a.values, label=&quot;no trick&quot;)
        plt.grid(); plt.legend(); plt.xlabel(&quot;step&quot;); plt.title(&quot;a&quot;);
    if i==2:
        plt.plot(h_trick.expectation.values, label=&quot;with rep trick&quot;)
        plt.plot(h_notrick.expectation.values, label=&quot;no trick&quot;)
        plt.grid(); plt.legend(); plt.xlabel(&quot;step&quot;); plt.title(&quot;expectation&quot;);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/minimizing expectation_23_0.png" src="../../../_images/minimizing expectation_23_0.png" />
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "p39"
        },
        kernelOptions: {
            kernelName: "p39",
            path: "./content/04.02 - Variational inference/research"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'p39'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Raúl Ramos / Universidad de Antioquia, Fabio González / Universidad Nacional de Colombia<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>