
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Probability and likelihood &#8212; Probabilistic Programming for Machine Learning</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/xglobal.css" />
    <link rel="stylesheet" type="text/css" href="../_static/spectre.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/spectre-exp.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/spectre-icons.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-MBFEZ3PF64"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-MBFEZ3PF64');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo-tf-udea-unal.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Probabilistic Programming for Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Welcome
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="outline.html">
   Course outline
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="M1-videolist.html">
   1 Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="M2-videolist.html">
   2 TF for Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="M3-videolist.html">
   3 Intuitions on Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="M4-videolist.html">
   4 Tensorflow Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="M5-videolist.html">
   5 Bayesian Modelling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="M6-videolist.html">
   6 Variational Inference
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/content/03.02 - NOTES 01 - Probability and likelihood.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/rramosp/ppdl/blob/main/content/03.02 - NOTES 01 - Probability and likelihood.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probability">
   Probability
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#likelihood">
   Likelihood
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#maximum-likelihood-estimation">
   Maximum likelihood estimation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#likelihood-on-continuous-distributions">
   Likelihood on continuous distributions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#likelihood-intuition">
   Likelihood intuition
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Probability and likelihood</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probability">
   Probability
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#likelihood">
   Likelihood
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#maximum-likelihood-estimation">
   Maximum likelihood estimation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#likelihood-on-continuous-distributions">
   Likelihood on continuous distributions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#likelihood-intuition">
   Likelihood intuition
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># init repo notebook
!git clone https://github.com/rramosp/ppdl.git &gt; /dev/null 2&gt; /dev/null
!mv -n ppdl/content/init.py ppdl/content/local . 2&gt; /dev/null
!pip install -r ppdl/content/requirements.txt &gt; /dev/null
</pre></div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="probability-and-likelihood">
<h1>Probability and likelihood<a class="headerlink" href="#probability-and-likelihood" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import pandas as pd
from rlxutils import subplots
import itertools
%matplotlib inline
</pre></div>
</div>
</div>
</div>
<p>We have data representing draws of a biased coin.</p>
<div class="math notranslate nohighlight">
\[x = [x_0, x_1, x_2, x_3]\]</div>
<p>but we <strong>don’t know</strong> the probability of the biased coin.</p>
<p>This is a Bernoulli distribution with <strong>unknown</strong> parameter <span class="math notranslate nohighlight">\(p\)</span>.</p>
<div class="math notranslate nohighlight">
\[x \sim \text{Bernoulli}(p)\]</div>
<p>The probability assigned to <span class="math notranslate nohighlight">\(x\)</span>, depends on a choice of <span class="math notranslate nohighlight">\(p\)</span></p>
<div class="math notranslate nohighlight">
\[P(x|p) = \prod_i P(x_i|p)\]</div>
<div class="section" id="probability">
<h2>Probability<a class="headerlink" href="#probability" title="Permalink to this headline">¶</a></h2>
<p>If we set <span class="math notranslate nohighlight">\(p\)</span> <strong>fixed</strong> and consider different datasets we have a <strong>discrete</strong> probability distribution, that assigns a probability to each dataset. And, in this very simple setting,  we have 16 possible datasets.</p>
<p>In all practical settings having an exhaustive list of all datasets is simply impossible. Think, for instance, of all possible datasets of 1000 customers described by age, profession, income, credit history,…. This would mean <strong>all</strong> combinations of <strong>all</strong> possible values for each feature.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>all_datasets = np.r_[list(itertools.product(*[[0,1]]*4))]
all_datasets
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0, 0, 0, 0],
       [0, 0, 0, 1],
       [0, 0, 1, 0],
       [0, 0, 1, 1],
       [0, 1, 0, 0],
       [0, 1, 0, 1],
       [0, 1, 1, 0],
       [0, 1, 1, 1],
       [1, 0, 0, 0],
       [1, 0, 0, 1],
       [1, 0, 1, 0],
       [1, 0, 1, 1],
       [1, 1, 0, 0],
       [1, 1, 0, 1],
       [1, 1, 1, 0],
       [1, 1, 1, 1]])
</pre></div>
</div>
</div>
</div>
<p>the conditional probability function</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>P_x_given_p = lambda x,p: np.prod(stats.bernoulli(p).pmf(x))
</pre></div>
</div>
</div>
</div>
<p>we fix p, so we have a function of x</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fixed_p=.3
P_x_fixed_p = lambda x: P_x_given_p(x, fixed_p)
</pre></div>
</div>
</div>
</div>
<p>and we <strong>DO</strong> have a discrete probability distribution for this fixed p.</p>
<p>The expression <span class="math notranslate nohighlight">\(P(x|p)\)</span> with a fixed <span class="math notranslate nohighlight">\(p\)</span> and varying <span class="math notranslate nohighlight">\(x\)</span> <strong>is a discrete probability distribution</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>probs = np.r_[[P_x_fixed_p(dataset) for dataset in all_datasets]]
print (&quot;all probabilities&quot;, probs)
print (&quot;\ncheck sum of probabilities&quot;, np.sum(probs))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>all probabilities [0.2401 0.1029 0.1029 0.0441 0.1029 0.0441 0.0441 0.0189 0.1029 0.0441
 0.0441 0.0189 0.0441 0.0189 0.0189 0.0081]

check sum of probabilities 0.9999999999999998
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>pd.Series(probs, index=[tuple(i) for i in all_datasets]).plot(figsize=(5,2), kind=&#39;bar&#39;)
plt.grid();plt.title(&quot;probability distribution P(x|p) with p fixed&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;probability distribution P(x|p) with p fixed&#39;)
</pre></div>
</div>
<img alt="../_images/03.02 - NOTES 01 - Probability and likelihood_11_1.png" src="../_images/03.02 - NOTES 01 - Probability and likelihood_11_1.png" />
</div>
</div>
</div>
<div class="section" id="likelihood">
<h2>Likelihood<a class="headerlink" href="#likelihood" title="Permalink to this headline">¶</a></h2>
<p>If we set <span class="math notranslate nohighlight">\(x\)</span> <strong>fixed</strong> and consider different values of <span class="math notranslate nohighlight">\(p\)</span> we have a <strong>likelihood</strong> function. This <strong>IS NOT</strong> a probability function</p>
<p>We fix <span class="math notranslate nohighlight">\(x\)</span>, so we have a function of <span class="math notranslate nohighlight">\(p\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fixed_x = np.r_[1,0,1,1]
likelihood = lambda p: P_x_given_p(fixed_x, p)
</pre></div>
</div>
</div>
</div>
<p>this is a continuous function, and it is not a probability distribution since it does not integrate to 1.</p>
<div class="math notranslate nohighlight">
\[\int_0^1 P(x_{fixed}|p) \text{d}p\]</div>
<p>in this case the integration is between 0 and 1 since, by definition, <span class="math notranslate nohighlight">\(p \in [0,1]\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>pr = np.linspace(.0,1., 100)
plt.plot(pr, [likelihood(pi) for pi in pr])
plt.title(&quot;likelihood&quot;); plt.grid();
plt.xlabel(&quot;p&quot;);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/03.02 - NOTES 01 - Probability and likelihood_15_0.png" src="../_images/03.02 - NOTES 01 - Probability and likelihood_15_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># the integral
from scipy.integrate import quad
quad(likelihood, 0,1)[0]
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.05
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="maximum-likelihood-estimation">
<h2>Maximum likelihood estimation<a class="headerlink" href="#maximum-likelihood-estimation" title="Permalink to this headline">¶</a></h2>
<p>but we can ask, what is the value of <span class="math notranslate nohighlight">\(p\)</span> that that assigns more probability to the data that we have seen?</p>
<div class="math notranslate nohighlight">
\[l(p) =  \prod_i P(x_i|p) \;\;\;\;\text{with }x\text{ fixed}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from scipy.optimize import minimize

# negative function for maximization
# constrained to possible values
r = minimize(lambda p: -likelihood(p), np.random.random(),
             constraints = ({&#39;type&#39;:&#39;ineq&#39;, &#39;fun&#39;: lambda p: p},
                            {&#39;type&#39;:&#39;ineq&#39;, &#39;fun&#39;: lambda p: 1-p} )
            
            ) 
r
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     fun: -0.10546865449586039
     jac: array([-0.00065521])
 message: &#39;Optimization terminated successfully&#39;
    nfev: 13
     nit: 6
    njev: 6
  status: 0
 success: True
       x: array([0.74970856])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>pr = np.linspace(.0,1., 100)
plt.plot(pr, [likelihood(pi) for pi in pr])
plt.title(&quot;likelihood&quot;); plt.grid();
plt.xlabel(&quot;p&quot;);
plt.axvline(r.x[0], color=&quot;black&quot;, label=&quot;MLE for p&quot;)
plt.legend()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x7fe756162400&gt;
</pre></div>
</div>
<img alt="../_images/03.02 - NOTES 01 - Probability and likelihood_19_1.png" src="../_images/03.02 - NOTES 01 - Probability and likelihood_19_1.png" />
</div>
</div>
<p>and one usually maximizes the <span class="math notranslate nohighlight">\(\log\)</span> likelihood since it is monotonic, nicely turns multiplications into summations and has much less numerical issues.</p>
<p>To maximize the likelihood, we maximize the log likelihood.</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(p) = \log l(p) =  \log \prod_i P(x_i|p) = \sum_i \log P(x_i|p)\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># original conditional distribution function
P_x_given_p = lambda x,p: np.prod(stats.bernoulli(p).pmf(x))

# log likelihood function
log_likelihood = lambda p: np.sum(np.log(stats.bernoulli(p).pmf(fixed_x)+1e-7))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.exp(log_likelihood(.2)), likelihood(.2)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.006400010400006, 0.006400000000000002)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>r = minimize(lambda p: -log_likelihood(p), np.random.random(), 
             constraints = ({&#39;type&#39;:&#39;ineq&#39;, &#39;fun&#39;: lambda x: x},
                            {&#39;type&#39;:&#39;ineq&#39;, &#39;fun&#39;: lambda x: 1-x} )
            )
r
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     fun: 2.2493397926615546
     jac: array([-0.00077778])
 message: &#39;Optimization terminated successfully&#39;
    nfev: 13
     nit: 6
    njev: 6
  status: 0
 success: True
       x: array([0.74996358])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plt.plot(pr, [log_likelihood(pi) for pi in pr])
plt.ylim(-10,0); plt.grid();
plt.axvline(r.x[0], color=&quot;black&quot;, label=&quot;MLE for p&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.lines.Line2D at 0x7fe7560921c0&gt;
</pre></div>
</div>
<img alt="../_images/03.02 - NOTES 01 - Probability and likelihood_24_1.png" src="../_images/03.02 - NOTES 01 - Probability and likelihood_24_1.png" />
</div>
</div>
</div>
<div class="section" id="likelihood-on-continuous-distributions">
<h2>Likelihood on continuous distributions<a class="headerlink" href="#likelihood-on-continuous-distributions" title="Permalink to this headline">¶</a></h2>
<p>let’s consider the data from the UCI ML repository, <a class="reference external" href="https://archive.ics.uci.edu/ml/datasets/Abalone">Abalone dataset</a></p>
<p>we will focus only on the marginal distribution of the variable <strong>length</strong>, and we will scale it so that it has values between 0 and 1</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>dataset = pd.read_csv(&quot;local/data/abalone.data.gz&quot;, 
                names=[&quot;sex&quot;, &quot;length&quot;, &quot;diameter&quot;, &quot;height&quot;, &quot;whole weight&quot;, &quot;shucked weight&quot;,
                         &quot;viscera weigth&quot;, &quot;shell weight&quot;, &quot;rings&quot;])

from sklearn.preprocessing import MinMaxScaler

x = dataset[&#39;diameter&#39;].values
x = MinMaxScaler(feature_range=(0.01,.99)).fit_transform(x.reshape(-1,1)).reshape(-1)
#x = x[np.random.permutation(len(x))[:1000]]
plt.hist(x, bins=20, density=True, alpha=.5);
plt.grid();
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/03.02 - NOTES 01 - Probability and likelihood_26_0.png" src="../_images/03.02 - NOTES 01 - Probability and likelihood_26_0.png" />
</div>
</div>
<p>We are told that <strong>MAYBE</strong> we can model this data with a <span class="math notranslate nohighlight">\(\mathcal{B}\)</span> (beta) distribution.</p>
<p>Seeing the shape of our histogram and the shapes produced by a <a class="reference external" href="https://en.wikipedia.org/wiki/Beta_distribution"><span class="math notranslate nohighlight">\(\mathcal{B}\)</span> distribution</a> this seems a reasonable assumption.</p>
<p>The beta distribution is governed by two parameters, <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span>.</p>
<p>We show now several <span class="math notranslate nohighlight">\(\mathcal{B}\)</span>, and the log likelihood is a function of two parameters</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(a,b) = \log \prod P(x|a,b)\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>loglik = lambda a,b: np.sum(np.log(stats.beta(a,b).pdf(x)+1e-7))

xr = np.linspace(0.01,.99,100)
plist = list(itertools.product(ar,br))
for ax,_ in subplots(18, n_cols=6):
    a,b = (np.random.random(2)+.01)*5
    beta = stats.beta(a=a, b=b)
    plt.plot(xr, beta.pdf(xr))
    plt.title(f&quot;a={a:.2f}, b={b:.2f}\nloglik={loglik(a,b):.2f}&quot;)
    plt.hist(x, bins=30, alpha=.5, density=True)
    plt.ylim(0,3.5)
    plt.grid();
    
plt.tight_layout()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/03.02 - NOTES 01 - Probability and likelihood_28_0.png" src="../_images/03.02 - NOTES 01 - Probability and likelihood_28_0.png" />
</div>
</div>
</div>
<div class="section" id="likelihood-intuition">
<h2>Likelihood intuition<a class="headerlink" href="#likelihood-intuition" title="Permalink to this headline">¶</a></h2>
<p>observe that parameters <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> producing functions more different to the histogram have must <strong>higher</strong> log likelihood.</p>
<p>Maximum Likelihood’s intuition is <strong>let’s assign what I see the highest possible probability</strong>:</p>
<p>We now find the MLE by brute force.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from progressbar import progressbar as pbar
ar = np.linspace(.5,10,200)
br = np.linspace(.5,10,200)
dr = (ar[1]-ar[0])*(br[1]-br[0])
r = np.r_[[loglik(a,b) for a,b in pbar(itertools.product(ar, br), max_value=len(ar)*len(br))]]
r=r.reshape(len(ar), len(br))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100% (40000 of 40000) |##################| Elapsed Time: 0:00:32 Time:  0:00:32
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>ai, bi = np.unravel_index(r.argmax(), r.shape)
ar[ai], br[bi]
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(4.796482412060302, 3.3643216080402008)
</pre></div>
</div>
</div>
</div>
<p>this is the <strong>search space</strong> and the values for <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> yielding the best likelihood.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plt.imshow(r, origin=&quot;lower&quot;)
plt.colorbar();
plt.xticks(range(len(ar))[::10], [f&quot;{i:.2f}&quot; for i in ar[::10]], rotation=&quot;vertical&quot;);
plt.yticks(range(len(br))[::10], [f&quot;{i:.2f}&quot; for i in br[::10]]);
plt.xlabel(&quot;a&quot;)
plt.ylabel(&quot;b&quot;)
plt.title(&quot;likelihood&quot;)
plt.scatter(bi, ai, marker=&quot;x&quot;, color=&quot;black&quot;, s=50, label=&quot;MLE&quot;)
plt.legend();
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/03.02 - NOTES 01 - Probability and likelihood_33_0.png" src="../_images/03.02 - NOTES 01 - Probability and likelihood_33_0.png" />
</div>
</div>
<p>observe how this makes intuitive sense, <strong>fitting</strong> reasonably well the distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>beta = stats.beta(a=ar[ai], b=br[bi])
plt.plot(xr, beta.pdf(xr))
plt.title(f&quot;a={a:.2f}, b={b:.2f}\nloglik={loglik(a,b):.2f}&quot;)
plt.hist(x, bins=30, alpha=.5, density=True)
plt.grid();
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/03.02 - NOTES 01 - Probability and likelihood_35_0.png" src="../_images/03.02 - NOTES 01 - Probability and likelihood_35_0.png" />
</div>
</div>
<p>Of course <strong>MLE</strong>, as any optimization, becomes <strong>much harder</strong> when we have a multivariate setting</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "p39"
        },
        kernelOptions: {
            kernelName: "p39",
            path: "./content"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'p39'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Raúl Ramos / Universidad de Antioquia, Fabio González / Universidad Nacional de Colombia<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>