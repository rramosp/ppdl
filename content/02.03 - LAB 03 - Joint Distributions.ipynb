{"cells": [{"cell_type": "code", "execution_count": null, "id": "2e75b6d3", "metadata": {}, "outputs": [], "source": ["# init repo notebook\n", "!git clone https://github.com/rramosp/ppdl.git > /dev/null 2> /dev/null\n", "!mv -n ppdl/content/init.py ppdl/content/local . 2> /dev/null\n", "!pip install -r ppdl/content/requirements.txt > /dev/null"]}, {"cell_type": "markdown", "id": "2f22c24b", "metadata": {}, "source": ["# Lab 02.03.3: Multiclass Bayesian Logistic Regression\n", "\n", "In this lab, we will implement a multilevel logistic regression model using the `tensorflow_probability`'s `JointDistribution` API."]}, {"cell_type": "code", "execution_count": null, "id": "dcb9234d", "metadata": {}, "outputs": [], "source": ["import inspect\n", "from rlxmoocapi import submit, session\n", "import numpy as np\n", "import tensorflow as tf\n", "import tensorflow_probability as tfp\n", "from sklearn.datasets import make_blobs\n", "from sklearn.neighbors import KernelDensity\n", "from sklearn.metrics import classification_report\n", "import matplotlib.pyplot as plt\n", "plt.style.use(\"ggplot\")\n", "\n", "tfd = tfp.distributions"]}, {"cell_type": "code", "execution_count": null, "id": "f92961d8", "metadata": {}, "outputs": [], "source": ["course_id = \"ppdl.v1\"\n", "endpoint = \"https://m5knaekxo6.execute-api.us-west-2.amazonaws.com/dev-v0001/rlxmooc\"\n", "lab = \"L02.03.03\""]}, {"cell_type": "code", "execution_count": null, "id": "e259a217", "metadata": {}, "outputs": [], "source": ["session.LoginSequence(\n", "    endpoint=endpoint,\n", "    course_id=course_id,\n", "    lab_id=lab,\n", "    varname=\"student\"\n", "    );"]}, {"cell_type": "markdown", "id": "666ddab0", "metadata": {}, "source": ["## Data Loading"]}, {"cell_type": "code", "execution_count": null, "id": "e4b0fb63", "metadata": {}, "outputs": [], "source": ["n_features = 2\n", "n_classes = 3\n", "X, y = make_blobs(\n", "        n_samples=500,\n", "        n_features=n_features,\n", "        centers=n_classes,\n", "        random_state=42\n", "        )"]}, {"cell_type": "markdown", "id": "45ed10c2", "metadata": {}, "source": ["We can visualize the data:"]}, {"cell_type": "code", "execution_count": null, "id": "e5cf2614", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n", "ax.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap=\"viridis\", alpha=0.5)\n", "ax.set_xlabel(\"$x_1$\")\n", "ax.set_ylabel(\"$x_2$\")"]}, {"cell_type": "markdown", "id": "3ada911f", "metadata": {}, "source": ["## Task 1: Implement a Logistic Regression Model\n", "\n", "In this task, you must define a logistic regression model using the `JointDistributionNamed` API, you must implement the following model:\n", "\n", "$$\n", "w \\sim \\mathcal{N}([0, 0], [1, 1])\\\\\n", "b \\sim \\mathcal{N}(0, 1)\\\\\n", "\\text{logits} = \\mathbf{w}\\cdot\\mathbf{x} + b\\\\\n", "y \\sim \\text{categorical}(\\text{logits})\n", "$$\n", "\n", "The model must have the following distributions: `w`, `b`, and `y`:"]}, {"cell_type": "code", "execution_count": null, "id": "64e65c8a", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["def prob_log_regression(x, n_features, n_classes):\n", "    # YOUR CODE HERE\n", "    model = ...\n", "    return model"]}, {"cell_type": "markdown", "id": "b10edd4d", "metadata": {}, "source": ["You can use the model to generate samples:"]}, {"cell_type": "code", "execution_count": null, "id": "4f92f9a8", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["model = prob_log_regression(X, n_features, n_classes)\n", "samples = model.sample(1)\n", "print(samples[\"y\"].shape)"]}, {"cell_type": "code", "execution_count": null, "id": "44b8949c", "metadata": {}, "outputs": [], "source": ["def grader1(functions, variables, caller_userid):\n", "    import tensorflow as tf\n", "    import tensorflow_probability as tfp\n", "    tfd = tfp.distributions\n", "\n", "    namespace = locals()\n", "    for f in functions.values():\n", "        exec(f, namespace)\n", "\n", "    n_features = 2\n", "    n_classes = 3\n", "    n_samples = 500\n", "    X, y = make_blobs(\n", "            n_samples=n_samples,\n", "            n_features=n_features,\n", "            centers=n_classes,\n", "            random_state=42\n", "            )\n", "    \n", "    prob_log_regression = namespace[\"prob_log_regression\"]\n", "    model_student = prob_log_regression(X, n_features, n_classes)\n", "    msg = \"Validating probabilistic model...</br>\"\n", "    if not isinstance(model_student, tfd.JointDistribution):\n", "        msg += \"<b>Your model is not a joint distribution.</b></br>\"\n", "        return 0, msg\n", "\n", "\n", "    dists = model_student.sample_distributions()[0]\n", "    expected_dists = {\n", "            \"w\": {\n", "                \"type\": tfd.Normal,\n", "                \"batch_shape\": [n_features, n_classes],\n", "                \"event_shape\": []\n", "                },\n", "            \"b\": {\n", "                \"type\": tfd.Normal,\n", "                \"batch_shape\": [n_classes],\n", "                \"event_shape\": []\n", "                },\n", "            \"y\": {\n", "                \"type\": tfd.Independent,\n", "                \"batch_shape\": [],\n", "                \"event_shape\": [n_samples],\n", "                }\n", "            }\n", "    for param, values in expected_dists.items():\n", "        if param not in dists:\n", "            msg += f\"<b>Your model doesn't contain the distribution '{param}'</b></br>\"\n", "            return 0, msg\n", "        if not isinstance(dists[param], values[\"type\"]):\n", "            msg += f\"<b>The distribution '{param}' is incorrect.</b>\"\n", "            return 0, msg\n", "\n", "        if list(dists[param].batch_shape) != values[\"batch_shape\"]:\n", "            msg += f\"<b>The distribution '{param}' has a wrong batch_shape.</b>\"\n", "            return 0, msg\n", "\n", "        if list(dists[param].event_shape) != values[\"event_shape\"]:\n", "            msg += f\"<b>The distribution '{param}' has a wrong event_shape.</b>\"\n", "            return 0, msg\n", "\n", "    return 5, msg + \"<b>Success!</b>\""]}, {"cell_type": "markdown", "id": "362eb462", "metadata": {}, "source": ["Use the following cell to grade your code:"]}, {"cell_type": "code", "execution_count": null, "id": "ecd9d497", "metadata": {}, "outputs": [], "source": ["teacher.set_grader(\n", "        teacher.course_id, lab, \"T1\",\n", "        inspect.getsource(grader1), \"grader1\",\n", "        source_functions, source_variables\n", "        )"]}, {"cell_type": "code", "execution_count": null, "id": "aa8d3bcc", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["student.submit_task(namespace=globals(), task_id=\"T1\");"]}, {"cell_type": "markdown", "id": "7df37a7a", "metadata": {}, "source": ["## Task 2: Markov Chain Monte Carlo\n", "\n", "Implement the `mcmc` function to train the model, you must use a Markov Chain Monte Carlo Strategy, We recommend using the `NoUTurnSampler` but feel free to experiment with the sampler."]}, {"cell_type": "code", "execution_count": null, "id": "c1513d2f", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["samples, log_probs = mcmc(\n", "        model=model,\n", "        y=y,\n", "        n_features=n_features,\n", "        n_classes=n_classes,\n", "        num_samples=10,\n", "        burning_steps=10,\n", "        )"]}, {"cell_type": "code", "execution_count": null, "id": "12c30a47", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["def grader2(functions, variables, caller_userid):\n", "    import tensorflow as tf\n", "    import numpy as np\n", "    import tensorflow_probability as tfp\n", "\n", "    tf.random.set_seed(0)\n", "    tfd = tfp.distributions\n", "\n", "    namespace = locals()\n", "    for f in functions.values():\n", "        exec(f, namespace)\n", "\n", "    # compare descriptive stats using the same base model.\n", "\n", "    n_features = 2\n", "    n_classes = 2\n", "    n_gen_samples = 100\n", "    burnout = 100\n", "\n", "    X = np.array([\n", "        [0, 0],\n", "        [0, 1],\n", "        [1, 0],\n", "        [1, 1]\n", "        ] * 10, dtype=\"float32\")\n", "    y = {\n", "            \"and\": np.array([0, 0, 0, 1] * 10),\n", "            \"or\": np.array([0, 1, 1, 1] * 10),\n", "            }\n", "\n", "    mcmc = namespace[\"mcmc\"]\n", "    msg = \"Validating mcmc procedure...</br>\"\n", "\n", "    for case, y_i in y.items():\n", "\n", "        model = tfd.JointDistributionNamedAutoBatched({\n", "            \"w\": tfd.Normal(loc=tf.zeros(shape=(n_features, n_classes)), scale=1.),\n", "            \"b\": tfd.Normal(loc=tf.zeros(shape=(n_classes, )), scale=1.),\n", "            \"y\": lambda b, w: tfd.Independent(\n", "                tfd.Categorical(logits=X @ w + b),\n", "                reinterpreted_batch_ndims=1\n", "                )\n", "            })\n", "        samples, log_probs = mcmc(\n", "                model=model,\n", "                y=y_i,\n", "                n_features=n_features,\n", "                n_classes=n_classes,\n", "                num_samples=n_gen_samples,\n", "                burning_steps=burnout,\n", "                )\n", "\n", "        if samples[0].shape != tf.TensorShape([n_gen_samples, n_features, n_classes]):\n", "            msg += \"<b>Your function returns samples with wrong w shapes.</b></br>\"\n", "            return 0, msg\n", "\n", "        if samples[1].shape != tf.TensorShape([n_gen_samples, n_classes]):\n", "            msg += \"<b>Your function returns samples with wrong b shapes.</b></br>\"\n", "            return 0, msg\n", "\n", "        if log_probs.shape != tf.TensorShape([n_gen_samples]):\n", "            msg += \"<b>Your function returns log_probs with wrong shape.</b></br>\"\n", "            return 0, msg\n", "\n", "        w = samples[0].numpy().mean(axis=0)\n", "        b = samples[1].numpy().mean(axis=0)\n", "\n", "        y_pred = np.argmax(X @ w + b, axis=1)\n", "\n", "        if (y_pred == y_i).sum() / y_i.size < 0.9:\n", "            msg += \"<b>The mcmc function does not optimize the specified model.</b></br>\"\n", "            msg += str(y_pred)\n", "            msg += str(y_i)\n", "            return 0, msg\n", "\n", "    return 5, msg + \"<b>Success!</b>\""]}, {"cell_type": "code", "execution_count": null, "id": "38696010", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["student.submit_task(namespace=globals(), task_id=\"T2\");"]}, {"cell_type": "markdown", "id": "873929bd", "metadata": {}, "source": ["## Task 3: MAP Predictions\n", "\n", "Compute the Maximum Aposteriori predictions of the parameters as follows:\n", "\n", "$$\n", "w_{map} = \\text{argmax}(\\text{kde}(w_{samples}))\\\\\n", "b_{map} = \\text{argmax}(\\text{kde}(w_{samples}))\\\\\n", "\\hat{y} = \\text{argmax}(\\text{softmax}(X, w_{map}, b_{map}))\n", "$$\n", "\n", "You must use `KernelDensity` for the estimation of the MAP parameters."]}, {"cell_type": "code", "execution_count": null, "id": "b97a474e", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["def kde(w_samples, b_samples, x, kernel=\"gaussian\", bandwidth=0.1):\n", "    # YOUR CODE HERE\n", "    preds = ...\n", "    return preds"]}, {"cell_type": "markdown", "id": "7e13eecc", "metadata": {}, "source": ["Let's generate some predictions:"]}, {"cell_type": "code", "execution_count": null, "id": "e8664155", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["preds = kde(samples[0].numpy(), samples[1].numpy(), X)"]}, {"cell_type": "code", "execution_count": null, "id": "c6095887", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["def grader3(functions, variables, caller_userid):\n", "    import numpy as np\n", "    import tensorflow as tf\n", "    from sklearn.datasets import make_blobs\n", "    from sklearn.neighbors import KernelDensity\n", "\n", "    namespace = locals()\n", "    for f in functions.values():\n", "        exec(f, namespace)\n", "\n", "    kde_student = namespace[\"kde\"]\n", "\n", "    def kde(w_samples, b_samples, x, kernel=\"gaussian\", bandwidth=0.1):\n", "        flat_w = w_samples.reshape(\n", "                (-1, np.prod(w_samples.shape[1:]))\n", "                )\n", "        w_densities = (\n", "                KernelDensity(kernel=kernel, bandwidth=bandwidth)\n", "                .fit(flat_w)\n", "                .score_samples(flat_w)\n", "                )\n", "        idx = np.argmax(w_densities)\n", "        w_map = w_samples[idx]\n", "\n", "        flat_b = b_samples.reshape(\n", "                (-1, np.prod(b_samples.shape[1:]))\n", "                )\n", "        b_densities = (\n", "                KernelDensity(kernel=kernel, bandwidth=bandwidth)\n", "                .fit(flat_b)\n", "                .score_samples(flat_b)\n", "                )\n", "        idx = np.argmax(b_densities)\n", "        b_map = b_samples[idx]\n", "\n", "        probs = tf.nn.softmax(x @ w_map + b_map)\n", "        preds = np.argmax(probs, axis=1)\n", "        return preds\n", "\n", "    msg = \"Testing your kde function with 10 random trials</br>\"\n", "\n", "    for _ in range(10):\n", "        n_samples = np.random.randint(1, 100)\n", "        n_gen_samples = np.random.randint(1, 10)\n", "        num_features = np.random.randint(2, 10)\n", "        num_classes = np.random.randint(2, 10)\n", "\n", "        samples_w = np.random.normal(size=(n_gen_samples, num_features, num_classes))\n", "        samples_b = np.random.normal(size=(n_gen_samples, num_classes))\n", "        x, _ = make_blobs(n_samples, num_features, centers=num_classes)\n", "\n", "        preds_student = kde_student(samples_w, samples_b, x)\n", "        preds_teacher = kde(samples_w, samples_b, x)\n", "\n", "        if not np.allclose(preds_student, preds_teacher):\n", "            msg += \"The MAP predictions do not match the expected results.\"\n", "            return 0, msg\n", "\n", "    return 5, msg + \"<b>Success!</b>\""]}, {"cell_type": "code", "execution_count": null, "id": "a2d7de54", "metadata": {}, "outputs": [], "source": ["student.submit_task(namespace=globals(), task_id=\"T3\");"]}, {"cell_type": "markdown", "id": "fad98e65", "metadata": {}, "source": ["## Model Evaluation\n", "\n", "Let's evaluate the MAP model"]}, {"cell_type": "code", "execution_count": null, "id": "fa90d94b", "metadata": {}, "outputs": [], "source": ["print(classification_report(y, preds))"]}], "metadata": {"jupytext": {"cell_metadata_filter": "-all", "main_language": "python", "notebook_metadata_filter": "-all"}}, "nbformat": 4, "nbformat_minor": 5}