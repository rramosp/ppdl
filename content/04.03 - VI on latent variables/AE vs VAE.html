
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AE and VAE implementations sharing the same architecture &#8212; Probabilistic Programming for Machine Learning</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/xglobal.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/spectre.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/spectre-exp.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/spectre-icons.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-MBFEZ3PF64"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-MBFEZ3PF64');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo-tf-udea-unal.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Probabilistic Programming for Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Welcome
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../outline.html">
   Course outline
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../M1-videolist.html">
   1 Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../M2-videolist.html">
   2 TF for Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../M3-videolist.html">
   3 Intuitions on Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../M4-videolist.html">
   4 Tensorflow Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../M5-videolist.html">
   5 Bayesian Modelling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../M6-videolist.html">
   6 Variational Inference
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/content/04.03 - VI on latent variables/AE vs VAE.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/rramosp/ppdl/blob/main/content/04.03 - VI on latent variables/AE vs VAE.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-both-vae-and-ae">
   train both VAE and AE
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#encoder-distributions-over-the-full-dataset">
   Encoder distributions over the full dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#output-for-a-selected-input-image">
   Output for a selected input image
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#shared-weights-for-vae-and-ae">
   Shared weights for VAE and AE
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fix-input-and-compute-gradients">
   Fix input and compute gradients
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-mean-gradient-of-vae-converges-to-the-gradient-of-ae">
     the mean gradient of VAE converges to the gradient of AE
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-mean-recostruction-loss-of-vae-seems-harder-to-converge-to-ae-loss">
     the mean recostruction loss of VAE seems harder to converge to AE loss
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>AE and VAE implementations sharing the same architecture</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-both-vae-and-ae">
   train both VAE and AE
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#encoder-distributions-over-the-full-dataset">
   Encoder distributions over the full dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#output-for-a-selected-input-image">
   Output for a selected input image
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#shared-weights-for-vae-and-ae">
   Shared weights for VAE and AE
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fix-input-and-compute-gradients">
   Fix input and compute gradients
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-mean-gradient-of-vae-converges-to-the-gradient-of-ae">
     the mean gradient of VAE converges to the gradient of AE
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-mean-recostruction-loss-of-vae-seems-harder-to-converge-to-ae-loss">
     the mean recostruction loss of VAE seems harder to converge to AE loss
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <p>from https://keras.io/examples/generative/vae/</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from progressbar import progressbar as pbar
import matplotlib.pyplot as plt
from rlxutils import subplots
from ppdl.models import transfer_weights
%matplotlib inline
from IPython.core.display import display, HTML
display(HTML(&quot;&lt;style&gt;.container { width:100% !important; }&lt;/style&gt;&quot;))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-01-17 18:47:12.059791: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcudart.so.11.0&#39;; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2022-01-17 18:47:12.059835: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
</pre></div>
</div>
<div class="output text_html"><style>.container { width:100% !important; }</style></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import os
os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;-1&quot;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>physical_devices = tf.config.list_physical_devices(&#39;GPU&#39;)
try:
  tf.config.experimental.set_memory_growth(physical_devices[0], True)
except:
  # Invalid device or cannot modify virtual devices once initialized.
  pass
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-01-17 18:47:16.273466: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcuda.so.1&#39;; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2022-01-17 18:47:16.273505: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-01-17 18:47:16.273533: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (rlxyoga): /proc/driver/nvidia/version does not exist
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()
mnist_digits = np.concatenate([x_train, x_test], axis=0)
mnist_digits = np.expand_dims(mnist_digits, -1).astype(&quot;float32&quot;) / 255
</pre></div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="ae-and-vae-implementations-sharing-the-same-architecture">
<h1>AE and VAE implementations sharing the same architecture<a class="headerlink" href="#ae-and-vae-implementations-sharing-the-same-architecture" title="Permalink to this headline">¶</a></h1>
<p>VAE has an extra layer to predict latent distribution std</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>tf.keras.backend.random_normal(shape=(3, 2))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-01-17 18:47:17.489938: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(3, 2), dtype=float32, numpy=
array([[-0.50825334,  0.04180132],
       [ 0.1010862 ,  0.8438553 ],
       [ 0.41337126, -0.02644788]], dtype=float32)&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>class Encoder(keras.Model):
    
    def __init__(self, latent_dim=2):
        super().__init__()
        self.conv1_layer = layers.Conv2D(32, 3, activation=&quot;relu&quot;, strides=2, padding=&quot;same&quot;, name=&quot;enc_conv1&quot;)
        self.conv2_layer = layers.Conv2D(64, 3, activation=&quot;relu&quot;, strides=2, padding=&quot;same&quot;, name=&quot;enc_conv2&quot;)
        self.dense_layer = layers.Dense(16, activation=&quot;relu&quot;, name=&quot;enc_dense1&quot;)

        self.output_layer = layers.Dense(latent_dim, name=&quot;enc_output&quot;)

    def call_stage(self, x):
        x = self.conv1_layer(x)
        x = self.conv2_layer(x)
        x = layers.Flatten()(x)
        x = self.dense_layer(x)
        return x
    
    def call(self, x):
        x = self.call_stage(x)
        x = self.output_layer(x)
        return x

class Sampling(layers.Layer):
    &quot;&quot;&quot;Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.&quot;&quot;&quot;
    def __init__(self, no_sampling=False, **kwargs):
        super().__init__(**kwargs)
        self.no_sampling = no_sampling

    def disable_sampling(self):
        self.no_sampling = True

    def enable_sampling(self):
        self.no_sampling = False

    def call(self, inputs):
        z_mean, z_log_var = inputs
        batch = tf.shape(z_mean)[0]
        dim = tf.shape(z_mean)[1]
        if self.no_sampling:
            return z_mean
        else:
            epsilon = tf.keras.backend.random_normal(shape=(batch, dim))
            return z_mean + tf.exp(0.5 * z_log_var) * epsilon
    
class VAE_Encoder(Encoder):
    
    def __init__(self, latent_dim=2):
        super().__init__(latent_dim=latent_dim)
        
        self.z_mean_layer    = self.output_layer
        self.z_log_var_layer = layers.Dense(latent_dim, name=&quot;enc_z_log_var&quot;)
        self.z_sampling_layer = Sampling(name=&quot;enc_sampling&quot;)

    def call(self, x):
        x = self.call_stage(x)
        z_mean    = self.z_mean_layer(x)
        z_log_var = self.z_log_var_layer(x)
        z_sample  = self.z_sampling_layer([z_mean, z_log_var])
        
        return [z_mean, z_log_var, z_sample]
    
class Decoder(keras.Model):
    
    def __init__(self, latent_dim=2):
        super().__init__()
        self.dense_layer = layers.Dense(7 * 7 * 64, activation=&quot;relu&quot;, name=&quot;dec_dense&quot;)
        self.convt1_layer = layers.Conv2DTranspose(64, 3, activation=&quot;relu&quot;, strides=2, padding=&quot;same&quot;, name=&quot;dec_convt1&quot;)
        self.convt2_layer = layers.Conv2DTranspose(32, 3, activation=&quot;relu&quot;, strides=2, padding=&quot;same&quot;, name=&quot;dec_convt2&quot;)
        self.convt_output_layer = layers.Conv2DTranspose(1, 3, activation=&quot;sigmoid&quot;, padding=&quot;same&quot;, name=&quot;dec_convt_output&quot;)
        
    def call(self, x):
        x = self.dense_layer(x)
        x = layers.Reshape((7, 7, 64))(x)
        x = self.convt1_layer(x)
        x = self.convt2_layer(x)
        x = self.convt_output_layer(x)
        return x
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>class VAE(keras.Model):
    def __init__(self, latent_dim=2, **kwargs):
        super().__init__(**kwargs)
        self.encoder = VAE_Encoder(latent_dim=latent_dim)
        self.decoder = Decoder()
        self.total_loss_tracker = keras.metrics.Mean(name=&quot;total_loss&quot;)
        self.reconstruction_loss_tracker = keras.metrics.Mean(
            name=&quot;reconstruction_loss&quot;
        )
        self.kl_loss_tracker = keras.metrics.Mean(name=&quot;kl_loss&quot;)

    def call(self, x):
        z_mean, z_log_var, z = self.encoder(x)
        return self.decoder(z)
        
    @property
    def metrics(self):
        return [
            self.total_loss_tracker,
            self.reconstruction_loss_tracker,
            self.kl_loss_tracker,
        ]

    def train_step(self, data):
        with tf.GradientTape() as tape:
            z_mean, z_log_var, z = self.encoder(data)
            reconstruction = self.decoder(z)
            reconstruction_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)
                )
            )
            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))
            total_loss = reconstruction_loss + kl_loss
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        self.reconstruction_loss_tracker.update_state(reconstruction_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        return {
            &quot;loss&quot;: self.total_loss_tracker.result(),
            &quot;reconstruction_loss&quot;: self.reconstruction_loss_tracker.result(),
            &quot;kl_loss&quot;: self.kl_loss_tracker.result(),
        }

class VAE_no_sampling(VAE):
    &quot;&quot;&quot;
    this does no sampling during training, it simply uses the mean obtain from the encoder
    &quot;&quot;&quot;
    def train_step(self, data):
        self.encoder.z_sampling_layer.disable_sampling()
        r = super().train_step(data)
        self.encoder.z_sampling_layer.enable_sampling()
        return r
</pre></div>
</div>
</div>
</div>
<p>observe that, in general, KL divergence between two gaussians (see https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians):</p>
<div class="math notranslate nohighlight">
\[K(d_1, d_2) = \log \frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2} { \sigma_2^2 } - \frac{1}{2}\]</div>
<p>and in our VAE <span class="math notranslate nohighlight">\(d_2 = \mathcal{N}(0,1)\)</span> and <span class="math notranslate nohighlight">\(d_1=\mathcal{N}(z_m, z_s)\)</span> (the latent space)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>class AE(keras.Model):
    def __init__(self, latent_dim=2, **kwargs):
        super().__init__(**kwargs)
        self.encoder = Encoder(latent_dim=latent_dim)
        self.decoder = Decoder()
        self.reconstruction_loss_tracker = keras.metrics.Mean(
            name=&quot;reconstruction_loss&quot;
        )
        self.reconstruction_loss_history = []

    def call(self, x):
        return self.decoder(self.encoder(x))
        
    @property
    def metrics(self):
        return [self.reconstruction_loss_tracker]

    def train_step(self, data):
        with tf.GradientTape() as tape:
            reconstruction = self(data)
            reconstruction_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)
                )
            )
        grads = tape.gradient(reconstruction_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.reconstruction_loss_tracker.update_state(reconstruction_loss)
        self.reconstruction_loss_history.append(self.reconstruction_loss_tracker.result())
        return {
            &quot;loss&quot;: self.reconstruction_loss_tracker.result()
        }
</pre></div>
</div>
</div>
</div>
<div class="section" id="train-both-vae-and-ae">
<h2>train both VAE and AE<a class="headerlink" href="#train-both-vae-and-ae" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from collections import defaultdict
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>class LogHistoryCallback(keras.callbacks.Callback):
    def __init__(self):
        self.history = defaultdict(lambda: [])
        
    def on_train_batch_end(self, batch, logs=None):
        for k,v in logs.items():
            self.history[k].append(v)        
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>latent_dim = 2
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>ae = AE(latent_dim=latent_dim)
ae_history = LogHistoryCallback()
ae.compile(optimizer=keras.optimizers.Adam())
ae.fit(mnist_digits, epochs=10, batch_size=128, callbacks=[ae_history])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/10
547/547 [==============================] - 29s 51ms/step - loss: 247.0607
Epoch 2/10
547/547 [==============================] - 28s 50ms/step - loss: 164.5102
Epoch 3/10
547/547 [==============================] - 27s 49ms/step - loss: 157.4806
Epoch 4/10
547/547 [==============================] - 27s 49ms/step - loss: 153.7700
Epoch 5/10
547/547 [==============================] - 26s 47ms/step - loss: 150.9073
Epoch 6/10
547/547 [==============================] - 27s 49ms/step - loss: 149.2074
Epoch 7/10
547/547 [==============================] - 27s 50ms/step - loss: 147.2194
Epoch 8/10
547/547 [==============================] - 27s 50ms/step - loss: 146.4270
Epoch 9/10
547/547 [==============================] - 27s 49ms/step - loss: 145.3725
Epoch 10/10
547/547 [==============================] - 27s 49ms/step - loss: 144.4022
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;keras.callbacks.History at 0x7f1fd0427df0&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>vae = VAE(latent_dim = latent_dim)
vae_history = LogHistoryCallback()
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit(mnist_digits, epochs=10, batch_size=128, callbacks=[vae_history])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/10
547/547 [==============================] - 28s 50ms/step - loss: 251.3182 - reconstruction_loss: 207.8073 - kl_loss: 3.3537
Epoch 2/10
547/547 [==============================] - 27s 50ms/step - loss: 189.7231 - reconstruction_loss: 184.4738 - kl_loss: 3.4414
Epoch 3/10
547/547 [==============================] - 27s 50ms/step - loss: 182.3991 - reconstruction_loss: 173.9269 - kl_loss: 4.3441
Epoch 4/10
547/547 [==============================] - 26s 47ms/step - loss: 167.2452 - reconstruction_loss: 159.8160 - kl_loss: 5.7697
Epoch 5/10
547/547 [==============================] - 26s 47ms/step - loss: 161.9323 - reconstruction_loss: 155.3109 - kl_loss: 6.0661
Epoch 6/10
547/547 [==============================] - 26s 47ms/step - loss: 159.7428 - reconstruction_loss: 153.1060 - kl_loss: 6.2183
Epoch 7/10
547/547 [==============================] - 26s 47ms/step - loss: 158.2384 - reconstruction_loss: 151.7047 - kl_loss: 6.2869
Epoch 8/10
547/547 [==============================] - 26s 47ms/step - loss: 156.7619 - reconstruction_loss: 150.5278 - kl_loss: 6.3329
Epoch 9/10
547/547 [==============================] - 26s 47ms/step - loss: 156.1608 - reconstruction_loss: 149.6693 - kl_loss: 6.3499
Epoch 10/10
547/547 [==============================] - 26s 47ms/step - loss: 155.5823 - reconstruction_loss: 148.8573 - kl_loss: 6.3755
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;keras.callbacks.History at 0x7f1fb87c29d0&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># VAE with no sampling during training --- seems to minimize faster both reconstruction and KL loss (overfits!!!)
nvae = VAE_no_sampling(latent_dim = latent_dim)
nvae_history = LogHistoryCallback()
nvae.compile(optimizer=keras.optimizers.Adam())
nvae.fit(mnist_digits, epochs=10, batch_size=128, callbacks=[nvae_history])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/10
547/547 [==============================] - 27s 47ms/step - loss: 242.8557 - reconstruction_loss: 189.1256 - kl_loss: 1.3945
Epoch 2/10
547/547 [==============================] - 26s 47ms/step - loss: 161.8632 - reconstruction_loss: 159.6056 - kl_loss: 0.4639
Epoch 3/10
547/547 [==============================] - 27s 49ms/step - loss: 155.5494 - reconstruction_loss: 154.0499 - kl_loss: 0.4691
Epoch 4/10
547/547 [==============================] - 27s 49ms/step - loss: 151.6743 - reconstruction_loss: 150.7937 - kl_loss: 0.4805
Epoch 5/10
547/547 [==============================] - 27s 50ms/step - loss: 150.0547 - reconstruction_loss: 148.9751 - kl_loss: 0.4693
Epoch 6/10
547/547 [==============================] - 27s 50ms/step - loss: 148.3027 - reconstruction_loss: 147.6532 - kl_loss: 0.4587
Epoch 7/10
547/547 [==============================] - 27s 49ms/step - loss: 147.1872 - reconstruction_loss: 146.6032 - kl_loss: 0.4516
Epoch 8/10
547/547 [==============================] - 27s 50ms/step - loss: 146.3313 - reconstruction_loss: 145.7848 - kl_loss: 0.4441
Epoch 9/10
547/547 [==============================] - 27s 50ms/step - loss: 145.4865 - reconstruction_loss: 145.1679 - kl_loss: 0.4421
Epoch 10/10
547/547 [==============================] - 28s 51ms/step - loss: 144.8976 - reconstruction_loss: 144.5220 - kl_loss: 0.4383
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;keras.callbacks.History at 0x7f1fb97d4280&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for k,v in vae_history.history.items():
    plt.plot(v, label=f&quot;VAE {k}&quot;)

for k,v in nvae_history.history.items():
    plt.plot(v, label=f&quot;nVAE {k}&quot;, ls=&quot;--&quot;)


plt.plot(ae_history.history[&#39;loss&#39;], label=&quot;AE reconstruction_loss&quot;, color=&quot;red&quot;, lw=4, alpha=.5)

plt.legend(loc=&#39;center left&#39;, bbox_to_anchor=(1, 0.5))
plt.grid();
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/AE vs VAE_19_0.png" src="../../_images/AE vs VAE_19_0.png" />
</div>
</div>
</div>
<div class="section" id="encoder-distributions-over-the-full-dataset">
<h2>Encoder distributions over the full dataset<a class="headerlink" href="#encoder-distributions-over-the-full-dataset" title="Permalink to this headline">¶</a></h2>
<p>one chart per <code class="docutils literal notranslate"><span class="pre">latent_dim</span></code></p>
<p>observe how AE <strong>tends</strong> to VAE</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>vaezm,vaezs,vaez = [i.numpy() for i in vae.encoder(mnist_digits)]
nvaezm,nvaezs,nvaez = [i.numpy() for i in nvae.encoder(mnist_digits)]
aez = ae.encoder(mnist_digits).numpy()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-01-17 19:00:58.768609: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1756160000 exceeds 10% of free system memory.
2022-01-17 19:00:58.999214: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1756160000 exceeds 10% of free system memory.
2022-01-17 19:00:59.252368: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1756160000 exceeds 10% of free system memory.
2022-01-17 19:01:00.362196: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1756160000 exceeds 10% of free system memory.
2022-01-17 19:01:00.662340: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1756160000 exceeds 10% of free system memory.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for ax,k in subplots(8, usizex=5, n_cols=4):
    if k==0:
        for i in range(latent_dim):
            plt.hist(aez[:,i], density=True, bins=100, alpha=.5);
        plt.title(&quot;AE encoder &quot;)
        plt.grid();
    if k==1:
        for i in range(latent_dim):
            plt.hist(vaez[:,i], density=True, bins=100, alpha=.5);
        plt.title(&quot;VAE encoder (sampling latent))&quot;)
        plt.grid();
    if k==2:
        for i in range(latent_dim):
            plt.hist(vaezm[:,i], density=True, bins=100, alpha=.5);
        plt.title(&quot;VAE encoder mean&quot;)
        plt.grid();
    if k==3:
        for i in range(latent_dim):
            plt.hist(np.exp(.5*vaezs[:,i]), density=True, bins=100, alpha=.5);
        plt.title(&quot;VAE encoder std&quot;)
        plt.grid();
    if k==4:
        plt.axis(&quot;off&quot;)
    if k==5:
        for i in range(latent_dim):
            plt.hist(nvaez[:,i], density=True, bins=100, alpha=.5);
        plt.title(&quot;nVAE encoder (sampling latent)&quot;)
        plt.grid();
    if k==6:
        for i in range(latent_dim):
            plt.hist(nvaezm[:,i], density=True, bins=100, alpha=.5);
        plt.title(&quot;nVAE encoder mean&quot;)
        plt.grid();
    if k==7:
        for i in range(latent_dim):
            plt.hist(np.exp(.5*nvaezs[:,i]), density=True, bins=100, alpha=.5);
        plt.title(&quot;nVAE encoder std&quot;)
        plt.grid();

plt.tight_layout()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/AE vs VAE_22_0.png" src="../../_images/AE vs VAE_22_0.png" />
</div>
</div>
</div>
<div class="section" id="output-for-a-selected-input-image">
<h2>Output for a selected input image<a class="headerlink" href="#output-for-a-selected-input-image" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>VAE and nVAE outputs a distribution of images (a distribution per pixel)</p></li>
<li><p>AE outputs a single image (a value per pixel)</p></li>
<li><p>nVAE has converged faster to the desired latent distribuition N(0,I)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># select one random input
idx = np.random.randint(len(mnist_digits))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># AE is deterministic, so we do inference just once and obtain one value for each output pixel
output_ae = ae(mnist_digits[idx:idx+1]).numpy()
output_ae.shape
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1, 28, 28, 1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># VAE is stochastic, so we do inference many times to understand the output distribution of each pixel
output_vae = vae(np.repeat(mnist_digits[idx:idx+1],10000, axis=0)).numpy()
output_vae.shape
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(10000, 28, 28, 1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># nVAE is stochastic, so we do inference many times to understand the output distribution of each pixel
output_nvae = nvae(np.repeat(mnist_digits[idx:idx+1],10000, axis=0)).numpy()
output_nvae.shape
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(10000, 28, 28, 1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for ax, i in subplots(6):
    if i==0:
        plt.imshow(mnist_digits[idx][:,:,0])
        plt.title(f&quot;input img idx={idx}&quot;)
        plt.colorbar();
    if i==1:
        plt.imshow(output_ae[0,:,:,0])
        plt.title(&quot;AE output&quot;)
        plt.colorbar();        
    if i==2:
        plt.imshow(output_vae[:,:,:,0].mean(axis=0))
        plt.title(&quot;VAE output pixel mean&quot;)
        plt.colorbar();        
    if i==3:
        plt.imshow(output_vae[:,:,:,0].std(axis=0))
        plt.title(&quot;VAE output pixel std&quot;)
        plt.colorbar();
    if i==4:
        plt.imshow(output_nvae[:,:,:,0].mean(axis=0))
        plt.title(&quot;nVAE output pixel mean&quot;)
        plt.colorbar();        
    if i==5:
        plt.imshow(output_nvae[:,:,:,0].std(axis=0))
        plt.title(&quot;nVAE output pixel std&quot;)
        plt.colorbar();
plt.tight_layout()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/AE vs VAE_28_0.png" src="../../_images/AE vs VAE_28_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plt.figure(figsize=(40,10))
plt.plot(output_ae.reshape(-1), color=&quot;blue&quot;, alpha=.5, lw=2, ls=&quot;--&quot;, label=&quot;AE&quot;)

om = output_vae.mean(axis=0).reshape(-1)
os = output_vae.std(axis=0).reshape(-1)
nom = output_nvae.mean(axis=0).reshape(-1)
nos = output_nvae.std(axis=0).reshape(-1)

plt.plot(om, color=&quot;red&quot;, alpha=.5, lw=1, label=&quot;VAE mean&quot;)
plt.fill_between(range(len(om)), om-3*os, om+3*os, color=&quot;orange&quot;, alpha=.5, label=&quot;VAE std&quot;)

plt.plot(nom, color=&quot;green&quot;, alpha=1, lw=1, label=&quot;nVAE mean&quot;)
plt.fill_between(range(len(nom)), nom-3*nos, nom+3*nos, color=&quot;green&quot;, alpha=.2, label=&quot;nVAE std&quot;)


plt.xlabel(&quot;pixel number&quot;)
plt.legend();
plt.grid();
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/AE vs VAE_29_0.png" src="../../_images/AE vs VAE_29_0.png" />
</div>
</div>
<p>show VAE distribution of pixel with largest mean and largest std</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>my,mx = output_vae.mean(axis=0).argmax()//28, output_vae.mean(axis=0).argmax()%28
sy,sx = output_vae.std(axis=0).argmax()//28, output_vae.std(axis=0).argmax()%28
ry1,rx1,ry2,rx2 = np.random.randint(28, size=4)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>vmin, vmax = output_vae.min(), np.max([output_ae.max(),1])+.1
vmin -= .1
for ax,i in subplots(4, usizex=5, usizey=4):
    if i==0:
        plt.hist(output_vae[:,my,mx,0], density=True, color=&quot;red&quot;, bins=100, alpha=.2, label=&quot;VAE value&quot;);
        plt.axvline(output_vae[:,my,mx,0].mean(), color=&quot;red&quot;, label=&quot;mean VAE value&quot;)
        plt.axvline(output_ae[0,my,mx,0], color=&quot;blue&quot;, label=&quot;AE value&quot;)
        plt.grid(); plt.legend();
        plt.title(f&quot;VAE distribution for pixel with largest mean\n y={my}, x={mx}&quot;)
        #plt.xlim(vmin, vmax)
    if i==1:
        plt.hist(output_vae[:,sy,sx,0], density=True, color=&quot;red&quot;, bins=100, alpha=.2, label=&quot;VAE value&quot;);
        plt.axvline(output_vae[:,sy,sx,0].mean(), color=&quot;red&quot;, label=&quot;mean VAE value&quot;)
        plt.axvline(output_ae[0,sy,sx,0], color=&quot;blue&quot;, label=&quot;AE value&quot;)
        plt.grid(); plt.legend();
        plt.title(f&quot;VAE distribution for pixel with largest std\n y={my}, x={mx}&quot;)
        #plt.xlim(vmin, vmax)
    if i==2:
        plt.hist(output_vae[:,ry1,rx1,0], density=True, color=&quot;red&quot;, bins=100, alpha=.2, label=&quot;VAE value&quot;);
        plt.axvline(output_vae[:,ry1,rx1,0].mean(), color=&quot;red&quot;, label=&quot;mean VAE value&quot;)
        plt.grid(); plt.legend();
        plt.title(f&quot;VAE distribution for a ranodm pixel\n y={ry1}, x={rx1}&quot;)
    if i==3:
        plt.hist(output_vae[:,ry2,rx2,0], density=True, color=&quot;red&quot;, bins=100, alpha=.2, label=&quot;VAE value&quot;);
        plt.axvline(output_vae[:,ry2,rx2,0].mean(), color=&quot;red&quot;, label=&quot;mean VAE value&quot;)
        plt.title(f&quot;VAE distribution for a ranodm pixel\n y={ry2}, x={rx2}&quot;)
        plt.axvline(output_ae[0,ry2,rx2,0], color=&quot;blue&quot;, label=&quot;AE value&quot;)
        plt.grid(); plt.legend();
plt.tight_layout()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/AE vs VAE_32_0.png" src="../../_images/AE vs VAE_32_0.png" />
</div>
</div>
</div>
<div class="section" id="shared-weights-for-vae-and-ae">
<h2>Shared weights for VAE and AE<a class="headerlink" href="#shared-weights-for-vae-and-ae" title="Permalink to this headline">¶</a></h2>
<p>transfer weights from VAE to AE (except VEA weights to estimate std <code class="docutils literal notranslate"><span class="pre">z_log_var</span></code>)</p>
<p>AE output is <strong>equivalent</strong> to VAE-mean output on the same input image</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>transfer_weights(from_model = vae.encoder, to_model = ae.encoder)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>layers transferred     [&#39;enc_conv1&#39;, &#39;enc_conv2&#39;, &#39;enc_dense1&#39;, &#39;enc_output&#39;]
layers not transferred [&#39;enc_z_log_var&#39;, &#39;enc_sampling&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>transfer_weights(from_model = vae.decoder, to_model = ae.decoder)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>layers transferred     [&#39;dec_dense&#39;, &#39;dec_convt1&#39;, &#39;dec_convt2&#39;, &#39;dec_convt_output&#39;]
layers not transferred []
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>output_ae = ae(mnist_digits[idx:idx+1]).numpy()
output_vae = vae(np.repeat(mnist_digits[idx:idx+1],10000, axis=0)).numpy()

plt.figure(figsize=(20,3))
plt.plot(output_ae.reshape(-1), color=&quot;blue&quot;, alpha=.5, lw=2, ls=&quot;--&quot;, label=&quot;AE&quot;)

om = output_vae.mean(axis=0).reshape(-1)
os = output_vae.std(axis=0).reshape(-1)
plt.plot(om, color=&quot;red&quot;, alpha=.5, lw=1, label=&quot;VAE mean&quot;)
plt.fill_between(range(len(om)), om-3*os, om+3*os, color=&quot;orange&quot;, alpha=.5, label=&quot;VAE std&quot;)
plt.xlabel(&quot;pixel number&quot;)
plt.legend();
plt.grid();
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/AE vs VAE_36_0.png" src="../../_images/AE vs VAE_36_0.png" />
</div>
</div>
</div>
<div class="section" id="fix-input-and-compute-gradients">
<h2>Fix input and compute gradients<a class="headerlink" href="#fix-input-and-compute-gradients" title="Permalink to this headline">¶</a></h2>
<p>procedure:</p>
<ul class="simple">
<li><p>select a random image</p></li>
<li><p>compute gradients with AE (deterministic, just once)</p></li>
<li><p>compute gradients with VAE (stochastic, do it many times)</p></li>
<li><p>for each differentiable parameter, mean VAE gradient corresponds to the AE gradient</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>img_input = mnist_digits[idx:idx+1]
img_output = vae(img_input)

for ax,i in subplots(10):
    if i == 0:
        plt.imshow(img_input[0])
        plt.title(&quot;input&quot;)
    if i &gt; 0:
        plt.imshow(vae(img_input)[0])
        plt.title(f&quot;output sample {i}&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/AE vs VAE_38_0.png" src="../../_images/AE vs VAE_38_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>get_wname = lambda x: &quot;/&quot;.join(x.name.split(&quot;/&quot;)[-2:])

def compute_reconstruction_gradient(model, img_input, weights=None):

    if weights is None:
        weights = model.trainable_weights
    
    with tf.GradientTape() as tape:
        img_output = model(img_input)
        reconstruction_loss = tf.reduce_mean(
            tf.reduce_sum(
                keras.losses.binary_crossentropy(img_input, img_output), axis=(1, 2)
            )
        )
    grads = tape.gradient(reconstruction_loss, weights)
    r = {get_wname(w): g.numpy() for g,w in zip(grads, weights)}
    r[&#39;loss&#39;] = reconstruction_loss.numpy()
    return r
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>w_ae = [get_wname(i) for i in ae.trainable_weights]
w_vae = [get_wname(i) for i in vae.trainable_weights]
w_names = list(set(w_ae).intersection(w_vae))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>vae_grads = [compute_reconstruction_gradient(vae, img_input) for _ in pbar(range(10000))]
ae_grads  =  compute_reconstruction_gradient(ae, img_input)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100% (10000 of 10000) |##################| Elapsed Time: 0:02:45 Time:  0:02:45
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def plotw(w_name):
    vgm = np.r_[[i[w_name] for i in vae_grads]].mean(axis=0).reshape(-1)
    vgs = np.r_[[i[w_name] for i in vae_grads]].std(axis=0).reshape(-1) 
    plt.figure(figsize=(20,3))
    
    plt.plot(vgm, color=&quot;red&quot;, alpha=.5, label=&quot;VAE mean&quot;)
    plt.fill_between(range(len(vgm)), vgm-3*vgs, vgm+3*vgs, color=&quot;orange&quot;, alpha=.5, label=&quot;VAE std&quot;)
    
    plt.plot(ae_grads[w_name].reshape(-1), color=&quot;blue&quot;, alpha=.5, label=&quot;AE&quot;)
    
    plt.title(f&quot;parameter {w_name}&quot;)
    plt.xlabel(&quot;parameter component number&quot;)
    plt.grid();
    plt.legend();
</pre></div>
</div>
</div>
</div>
<div class="section" id="the-mean-gradient-of-vae-converges-to-the-gradient-of-ae">
<h3>the mean gradient of VAE converges to the gradient of AE<a class="headerlink" href="#the-mean-gradient-of-vae-converges-to-the-gradient-of-ae" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for w_name in w_names:
    plotw(w_name)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/AE vs VAE_44_0.png" src="../../_images/AE vs VAE_44_0.png" />
<img alt="../../_images/AE vs VAE_44_1.png" src="../../_images/AE vs VAE_44_1.png" />
<img alt="../../_images/AE vs VAE_44_2.png" src="../../_images/AE vs VAE_44_2.png" />
<img alt="../../_images/AE vs VAE_44_3.png" src="../../_images/AE vs VAE_44_3.png" />
<img alt="../../_images/AE vs VAE_44_4.png" src="../../_images/AE vs VAE_44_4.png" />
<img alt="../../_images/AE vs VAE_44_5.png" src="../../_images/AE vs VAE_44_5.png" />
<img alt="../../_images/AE vs VAE_44_6.png" src="../../_images/AE vs VAE_44_6.png" />
<img alt="../../_images/AE vs VAE_44_7.png" src="../../_images/AE vs VAE_44_7.png" />
<img alt="../../_images/AE vs VAE_44_8.png" src="../../_images/AE vs VAE_44_8.png" />
<img alt="../../_images/AE vs VAE_44_9.png" src="../../_images/AE vs VAE_44_9.png" />
<img alt="../../_images/AE vs VAE_44_10.png" src="../../_images/AE vs VAE_44_10.png" />
<img alt="../../_images/AE vs VAE_44_11.png" src="../../_images/AE vs VAE_44_11.png" />
<img alt="../../_images/AE vs VAE_44_12.png" src="../../_images/AE vs VAE_44_12.png" />
<img alt="../../_images/AE vs VAE_44_13.png" src="../../_images/AE vs VAE_44_13.png" />
<img alt="../../_images/AE vs VAE_44_14.png" src="../../_images/AE vs VAE_44_14.png" />
<img alt="../../_images/AE vs VAE_44_15.png" src="../../_images/AE vs VAE_44_15.png" />
</div>
</div>
</div>
<div class="section" id="the-mean-recostruction-loss-of-vae-seems-harder-to-converge-to-ae-loss">
<h3>the mean recostruction loss of VAE seems harder to converge to AE loss<a class="headerlink" href="#the-mean-recostruction-loss-of-vae-seems-harder-to-converge-to-ae-loss" title="Permalink to this headline">¶</a></h3>
<p>additionally recall that:</p>
<ul class="simple">
<li><p>VAE loss has two terms: reconstruction and KL-divergence, while AE only uses the reconstruction loss</p></li>
<li><p>thus, we are only comparing the reconstruction loss</p></li>
<li><p>there is high variability on the loss, only with a large sample we can see that it converges</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>vloss = np.r_[[i[&#39;loss&#39;] for i in vae_grads]]
plt.hist(vloss, bins=100, alpha=.5, label=&quot;VAE loss&quot;);
plt.axvline(vloss.mean(), color=&quot;red&quot;, label=&quot;VAE mean loss&quot;)
plt.axvline(ae_grads[&#39;loss&#39;], color=&quot;blue&quot;, label=&quot;AE loss&quot;)
plt.grid(); plt.legend();
plt.xlabel(&quot;loss values&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 0, &#39;loss values&#39;)
</pre></div>
</div>
<img alt="../../_images/AE vs VAE_46_1.png" src="../../_images/AE vs VAE_46_1.png" />
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/04.03 - VI on latent variables"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Raúl Ramos / Universidad de Antioquia, Fabio González / Universidad Nacional de Colombia<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>