
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>&lt;no title&gt; &#8212; Probabilistic Programming for Machine Learning</title>
    
  <link href="../../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/xglobal.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/spectre.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/spectre-exp.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/spectre-icons.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-MBFEZ3PF64"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-MBFEZ3PF64');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../../_static/logo-tf-udea-unal.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Probabilistic Programming for Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../intro.html">
   Welcome
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../content/outline.html">
   Course outline
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../content/M1-videolist.html">
   1 Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../content/M2-videolist.html">
   2 TF for Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../content/M3-videolist.html">
   3 Intuitions on Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../content/M4-videolist.html">
   4 Tensorflow Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../content/M5-videolist.html">
   5 Bayesian Modelling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../content/M6-videolist.html">
   6 Variational Inference
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../../_sources/anims/src/02.01-TF-core/02.01-ANIM-01-ML-algorithm-design/script.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="simple visible nav section-nav flex-column">
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1><no title></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="simple visible nav section-nav flex-column">
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show on top &quot;Designing machine learning algorithms&quot;
show scientist
</pre></div>
</div>
<p>[0:0] Vamos a ponernos el sobrero de la persona que quiere diseñar un nuevo algoritmo de machine learning. Y vamos a ver el proceso por el cual se plantea esto, desde que tenemos una intuición hasta que finalmente armamos un procedimiento de entrenamiento de un modelo basado en datos.</p>
<p>[0:24] Cómo vamos a ver, las máquinas NO aprenden, sino que se calibran con algoritmos.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show in big &quot;MACHINES DO NOT LEARN&quot;
</pre></div>
</div>
<p>[0:31] Y esta distinción es muy importante, porque denota que estamos ante un proceso gobernado por la computación, las matemáticas, la estadística, …, es decir, por los ingenieros y los científicos que trabajamos en esto, y no por ejércitos de máquinas que van a conquistar el mundo.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show comic below make robot vanish
</pre></div>
</div>
<p><img alt="" src="../../../../_images/20220509142542.png" /></p>
<p>[0:53] Prácticamente todos los algoritmos de machine learning son diseñados el procedimiento general que vamos a ver en este video. Y esto incluye la regresión lineal, los árboles de decisión, las máquinas de soporte vectorial, las redes neuronales,  “Random Forests”, “Nearest Neighbors”, en fin …</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>delete robot, show in random positions &quot;linear regression&quot;, 
decision trees, support vector machines, neural networks, etc. 
</pre></div>
</div>
<p>[1:18] Por supuesto, dentro de este proceso, cada algoritmo tiene tienes sus retos y particularidades, pero el esquema general el proceso es el mismo.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>clear and show following figure
</pre></div>
</div>
<p><img alt="" src="../../../../_images/20220509105556.png" /></p>
<p>[1:37] Veamos entonces cómo es esto.</p>
<p>Partimos de una tarea que se plantea. Tomemos como ejemplo una tarea de regresión muy sencilla.</p>
<p>[1:50] Dada una entrada (la longitud de unos bichitos), a la que llamamos <span class="math notranslate nohighlight">\(x^{i}\)</span>, queremos predecir otra variable: su densidad de escamas, que llamamos <span class="math notranslate nohighlight">\(y^{i}\)</span>.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show equation below
</pre></div>
</div>
<p><span class="math notranslate nohighlight">\(x^{i}\)</span>= length, <span class="math notranslate nohighlight">\(y^{i}\)</span> = density</p>
<p>[2:07] y el superíndice <span class="math notranslate nohighlight">\(i\)</span> para denotar a cada bichito. Tenemos <span class="math notranslate nohighlight">\(N\)</span> bichitos, y por tanto <span class="math notranslate nohighlight">\(N\)</span> pares de <span class="math notranslate nohighlight">\(x\)</span> e <span class="math notranslate nohighlight">\(y\)</span>, uno para cada bichito al que le medimos la longitud y la densidad de escamas.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show equation below
</pre></div>
</div>
<p><span class="math notranslate nohighlight">\((x^{0}, y^{0})\)</span>, with <span class="math notranslate nohighlight">\(i\)</span> in (0,…,N-1), when we have N bugs</p>
<p>[2:30] la idea es que la densidad de escamas es muy costosa de medir (hay que contarlas) y por eso queremos un modelo predictivo.</p>
<p>[2:43] Hemos hecho una campaña de adquisición de datos etiquetados, y estamos planteando una tarea de aprendizaje supervisado.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show &quot;supervised machine learning&quot;
</pre></div>
</div>
<p>[2:58] Lo primero que tenemos que hacer es definir cual es la suposición inicial, y la estructura de nuestro modelo.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show at left &quot;1. Define model structure&quot;
</pre></div>
</div>
<p>[3:10] en este caso, vamos a asumir que la relación entre la entrada y la salida es lineal, que es el caso más sencillo. En realidad, en nuestros datos vemos que la estructura <strong>NO ES LINEAL</strong>, si no cuadrática,</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show quadratic fit.
</pre></div>
</div>
<p>[3:27] con lo cual estamos partiendo de un supuesto que <strong>NO SE AJUSTA A ESTOS DATOS</strong> pero eso lo vemos porque tenemos un ejemplo de juguete con sólo una variable y podemos visualizarlos. En la inmensa mayoría de los casos, esto ni lo sabemos ni lo podemos ver.</p>
<p>[3:50] De hecho, elegir un modelo (o algoritmo) que parta de un supuesto que se ajuste a los datos que tengo en un cierto momento, es en sí uno de los retos principales al abordar el desarrollo de cualqueir modelo predictivo con machine learning. Si te suenan las nociones de overfitting y underfitting, son las que en la práctica, nos dan pistas sobre qué modelos pueden ser mejores o peores para un problema concreto.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show words &#39;overfitting&#39; &#39;underfitting&#39;
</pre></div>
</div>
<p>[4:30] En el notebook a continuación vamos a implementar estas ideas y reparar esto, pero por ahora, sigamos con esta suposición y veamos donde nos lleva.</p>
<p>[4:41] Segundo paso, tenemos que definir la <strong>parametrización</strong> de modelo. Es decir, cuantos parámetros necesitamos para describir una solución</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show  at left &quot;2. Define model parametrization&quot; below 1
</pre></div>
</div>
<p>[4:51] En este caso, cualquier solución viene dada por una linea recta en el plano de longitud y densidad, que es este que vemos. Y en este plano 2D, para describir cualquier línea necesitamos 2 parámetros, que llamamos <span class="math notranslate nohighlight">\(\theta_0\)</span> y <span class="math notranslate nohighlight">\(\theta_1\)</span>.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show text theta1: slope, theta0: intercept
</pre></div>
</div>
<p>[5:13] Distintos valores de los parámetros nos dan distintas rectas. Todas estas son posibles soluciones, cada una descrita por dos parámetros.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show random lines on the plane, which the value of $theta_0$ y $theta_1$ for each solution
</pre></div>
</div>
<p>[5:30] En este caso, tenemos una interpretación muy directa de los parámetros: son el intercepto y la pendiente. En muchas ocasiones no vamos a poder interpretar los parámetros de un modelo tan directamente. Sin ir más lejos, a interpretaciòn de los parámetros en las redes neuronales es todo un tema de investigación.</p>
<p>[5:54] Por ejemplo, esta solución</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show line far off the data
</pre></div>
</div>
<p>vemos intuitivamente que no se ajusta muy bien a los datos.</p>
<p>[6:00] mientras que esta</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show line better fit
</pre></div>
</div>
<p>se ajusta mejor.</p>
<p>[6:06] En este punto, el objeto de machine learning es encontrar el modelo, DENTROS DE LA CLASE DE MODELOS QUE HEMOS SELECCIONADO (que son las rectas en este caso), que mejor se ajuste a los datos.</p>
<p>[6:25] O dicho de otro modo, cuales son los parámetros que describen la recta que mejor se ajusta a los datos.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show best line fit, with params.
</pre></div>
</div>
<p>[6:38] para esto necestaremos dos cosas.</p>
<p>una, es definir operativamente cómo se obtiene una predicción, dada una entrada <span class="math notranslate nohighlight">\(x^{(i)}\)</span> (una longitud) y unos valores para los parámetros</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show left &quot;3. Define how to predict&quot; below 2

show several times, dash line on random x up to regression line, left to y_hat
</pre></div>
</div>
<p>[7:00] en este caso, es la misma ecuación de una recta que nos da la predicción.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show next equation
</pre></div>
</div>
<p><span class="math notranslate nohighlight">\(\hat{y}^{(i)} = \theta_0 + \theta_1 x^{(i)}\)</span></p>
<p>[7:12] fíjate que usamos <span class="math notranslate nohighlight">\(y^{(i)}\)</span> para denotar el valor real, y <span class="math notranslate nohighlight">\(\hat{y}^{(i)}\)</span> con el sobrerito para denotar el valor predicho por el modelo.</p>
<p>[7:44] y lo otro que necesitamos, es definir cómo medir el error entre la predicción <span class="math notranslate nohighlight">\(\hat{y}^{(i)}\)</span> y el valor real <span class="math notranslate nohighlight">\(y^{(i)}\)</span>. Esta es la función de coste, o pérdida (loss, en inglés)</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show left &quot;4. Define cost (or loss) function&quot; below 2
</pre></div>
</div>
<p>[7:58] Hay muchas maneras de medir los errores, y el error cuadrático es una de ellas</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show next equation
</pre></div>
</div>
<p><span class="math notranslate nohighlight">\(error^{(i)} = (\hat{y}^{(i)} - y^{(i)})^2\)</span></p>
<p>[8:17] y como tenemos <span class="math notranslate nohighlight">\(N\)</span> bichitos, promediamos el error en la predicción de cada bichito</p>
<p><span class="math notranslate nohighlight">\(\text{loss}(\theta_0, \theta_1) = \frac{1}{N}\sum_{i=0}^{N-1} (\hat{y}^{(i)} - y^{(i)})^2\)</span></p>
<p>[8:31] Fíjate en dos detalles aquí:</p>
<ol class="simple">
<li><p>elevamos al cuadrado para evitar que errores positivos se compenses con errores negativos en la suma</p></li>
</ol>
<p>[8:45] 2) la pérdida es función de los parámetros del modelo. Es decir, ASUMIMOS que los datos están fijos.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show enlarge theta0 y theta1
</pre></div>
</div>
<p>[8:57] Esto es CONSECUENCIA de lo que estamos buscando, recuerda que queremos los parámetros que describan la recta (o nuestro modelo) que produzca menos error.</p>
<p>[9:10] Para ello vamos a ir moviendo los valores de los parámetros hasta encontrar algunos que nos satisfagan.</p>
<p>[9:24] Es decir, durante el proceso por el cual vamos a buscar dichos valores para los parámetros, no vamos a modificar los datos</p>
<p>[9:40] ahora estamos en disposición de expresar de manera más rigurosa lo que estamos buscando</p>
<p><span class="math notranslate nohighlight">\(\text{arg min}_{\theta_0 \theta_1} \text{loss}(\theta_0, \theta_1)\)</span></p>
<p>[9:55] es decir, hemos formulado nuestra búsqueda de un modelo que haga una cierta predicción como un problema de optimización.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show 5. Optimize below 4
</pre></div>
</div>
<p>[10:08] Con lo que machine Learning es fundamentalmente un ejercicio de optimización matemática sobre un conjunto de datos. Entrenar un modelo, es en realidad OPTIMIZAR los parámetros de un modelo respecto a una función de pérdida usando unos datos concretos.</p>
<p>[10:32] Dos detalles que son muy importantes.</p>
<p>Primero, optimizar es complejo, y existe un área muy extensa de las matemáticas dedicada a ello. La gran mayoría de los métodos que usaremos para optimizar nos requieren hallar las derivadas de los parámetros respecto a la pérdida. Es decir, el gradiente</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show equation below
</pre></div>
</div>
<p><span class="math notranslate nohighlight">\(\nabla = [\frac{\partial \text{loss}}{\theta_0}\)</span>, <span class="math notranslate nohighlight">\(\frac{\partial \text{loss}}{\theta_1}]\)</span>.</p>
<p>[10:55] Es decir, necesitamos conocer cómo varía la función de pérdida cuando variamos los parámetros, para poder encontrar los que hacen que la pérdida sea menor.</p>
<p>[11:14] En nuestro ejemplo, obtener el gradiente no es excesivamente complejo, aunque quizá sea algo tedioso. Si te atreves, trata de derivarla tú mismo a mano y la compruebas con esta.</p>
<p>[11:30] pero por supuesto con otros modelos y con más parámetros y descriptores de los datos (aquí solo tenemos uno, la longitud) esto se vuelve en un reto importante.</p>
<p>[11:41] por tanto, un paso necesario en este proceso es la obtención del gradiente, o sea las derivadas parciales de la pérdida respecto a los parámetros</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show 4. computing the gradient expressions, between 4 and 5, transform 5 into 6.
</pre></div>
</div>
<p>[11:57] fíjate que la complejidad de obtener el gradiente depende de:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show each point below
</pre></div>
</div>
<p>[12:03] - la complejidad de la función de predicción
[12:11]- la complejidad de la función de pérdida
[12:16] - el número de descriptores de nuestros datos
[12:20] - el número de parámetros de nuestros modelos.</p>
<p>para poner esto en perspectiva, date cuenta de que</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show each point below
</pre></div>
</div>
<p>[12:32]- una imagen de 200x200 pixeles y 3 canales de color (RGB), tiene 200x200x3 descriptores
[12:47] - AlexNet, que fue una de las primeras redes convolucionales hace ya 10 años, tiene 61M de parámetros.</p>
<p>[13:15] Pero por otro lado, algo positivo, fíjate que las estructuras que estamos manejando son muy regulares.</p>
<p>nuestros datos de entrada <span class="math notranslate nohighlight">\(x\)</span> suelen estar representados por alguna estructura matricial. puede ser tabular (m descriptores x n datos).</p>
<p>[13:40] Aquí cada xi (x0, x1, etc.) tiene <span class="math notranslate nohighlight">\(m\)</span> descriptores, por tanto, tenemos una matrix de m columnas y n filas, por ejemplo n pacientes, con m datos clìnicos cada paciente</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show X matrix ... n rows, m columns
</pre></div>
</div>
<p>[13:53] o de más dimensiones, por ejemplo si tenemos imágenes. Por ejemplo, un conjunto de imàgenes RGB tiene 4 dimensiones (nùmero de imàgenes, alto, ancho, y número de canales)</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show stacked images
</pre></div>
</div>
<p>y en la mayoría de los casos las funciones de predicción y de pérdida se pueden expresar de manera matricial.</p>
<p>[14:18] Por ejemplo, esta es la expresión del gradiente de la regresión linea, asumiendo m descriptores</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show equation below
</pre></div>
</div>
<p><span class="math notranslate nohighlight">\(\nabla \theta = X(X-1....)\)</span></p>
<p>[14:35] donde <span class="math notranslate nohighlight">\(\theta\)</span> es el vector con todos los parámetros. Tendremos <span class="math notranslate nohighlight">\(m\)</span> parámetros. <span class="math notranslate nohighlight">\(X\)</span> es la matrix con todos los datos, será de m columnas for n filas</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show eqs below
</pre></div>
</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(X \in \mathbb{R}^{n \times m}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(y \in \mathbb{R}^{n}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\theta \in \mathbb{R}^{m}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\nabla \theta \in \mathbb{R}^{n}\)</span></p></li>
</ul>
<p>con lo que en realidad estamos definiendo gradientes sobre estructuras matriciales de más o menos complejidad.</p>
<p>[15:07] En la actualidad, existen paquetes y librerías de programación que nos permiten cálculo simbólico (es decir, obtener derivadas, integrales, etc.) y que también nos permiten optimizar.</p>
<p>[15:20] Por ejemplo en Python tenemos sympy y scipy.otimize</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show verbatim sympy and scipy.optimize
</pre></div>
</div>
<p>con los que de hecho vamos jugar en los notebooks siguientes.</p>
<p>[15:35] Pero en general estos paquetes fallan cuando los usamos con problemas y algoritmos de machine learning. Ya que, por naturaleza, acabamos construyendo expresiones con muchas matrices y muchos parámetros. Y estos paquetes son genéricos, también resuelven sistemas de ecuaciones, ecuaciones diferenciales, en fin … Y cuando los usamos para resolver problemas de machine learning pues nos encontramos con infinidad de problemas (de memoria, de tiempo de cómputo, etc.)</p>
<p>[16:25] Por eso se desarrollaron paquetes como TF y Torch (y otros), que en realidad son librerías de cómputo simbólico (hacen auto-diferenciación, pero no el reto de operaciones simbòlicas como la integración, resolución de ecuanciones y demás) y de optimización, especialmente diseñadas para tratar con las expresiones y estructuras que surgen en los problemas de machine learning. Es decir, con gradientes y matrices de gran tamaño.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> show logos TF torch
</pre></div>
</div>
<p>[17:47] En resumen, estamos planteando problemas de optimización matemática con datos y expresiones de un cierto tipo.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    show scientist
</pre></div>
</div>
<p>[17:57] Nuestra capacidad de resolverlas dependerá de varias cosas:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show next bullet points
</pre></div>
</div>
<p>[18:02] de diseñar o elegir la estructura de modelo correcta (una red neural con tantas capas, un árbol de decisión con tal configuración, etc.)</p>
<p>[18:12] de elegir bien la función de pérdida que queremos optimizar.</p>
<p>[18:15] de elegir bien con qué datos vamos a optimizar.</p>
<p>[18:20] de poder obtener los gradientes de manera eficiente y correcta.</p>
<p>[18:24] de usar algoritmos de optimización adecuados.</p>
<p>[18:28] de usar los frameworks computacionales de los que disponemos adecuadamente.</p>
<p>[18:50] En fin, de procesos de ciencia e ingeniería que funcionarán mejor o peor en tanto en cuanto los entendamos y sepamos manejarlos en el contexto de aplicación que tengamos.</p>
<p>[19:03] Y te recuerdo el proceso:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show bullet points of process
</pre></div>
</div>
<p>[19:17] Es decir, las máquinas no aprenden,somos NOSOTROS los que las usamos para calibrar algoritmos con datos, mediante un proceso computacional de optimización matemática.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>show smile
</pre></div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./anims/src/02.01-TF-core/02.01-ANIM-01-ML-algorithm-design"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Raúl Ramos / Universidad de Antioquia, Fabio González / Universidad Nacional de Colombia<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>