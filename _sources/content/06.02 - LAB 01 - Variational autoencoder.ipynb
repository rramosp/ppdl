{"cells": [{"cell_type": "code", "execution_count": null, "id": "2ce1d064", "metadata": {}, "outputs": [], "source": ["# init repo notebook\n", "!git clone https://github.com/rramosp/ppdl.git > /dev/null 2> /dev/null\n", "!mv -n ppdl/content/init.py ppdl/content/local . 2> /dev/null\n", "!pip install -r ppdl/content/requirements.txt > /dev/null"]}, {"cell_type": "markdown", "id": "0e260fdd", "metadata": {}, "source": ["# LAB 06.01.02 - Variational Autoencoder\n", "\n", "In this lab, you'll see the relationship between classical unsupervised methods like PCA and the variational autoencoder (VAE).\n", "\n", "First, let us import the grading libraries:"]}, {"cell_type": "code", "execution_count": null, "id": "32f527f2", "metadata": {}, "outputs": [], "source": ["import inspect\n", "from rlxmoocapi import submit, session\n", "\n", "course_id = \"ppdl.v1\"\n", "endpoint = \"https://m5knaekxo6.execute-api.us-west-2.amazonaws.com/dev-v0001/rlxmooc\"\n", "lab = \"L06.01.02\""]}, {"cell_type": "markdown", "id": "5cc060bb", "metadata": {}, "source": ["Please, use your credentials to log into the platform:"]}, {"cell_type": "code", "execution_count": null, "id": "60c25dd4", "metadata": {}, "outputs": [], "source": ["session.LoginSequence(\n", "    endpoint=endpoint,\n", "    course_id=course_id,\n", "    lab_id=lab,\n", "    varname=\"student\"\n", "    );"]}, {"cell_type": "code", "execution_count": null, "id": "8936eca5", "metadata": {}, "outputs": [], "source": ["import os\n", "ses = session.Session(endpoint)\n", "teacher = ses.login(\n", "        user_id=os.environ[\"USER_ID\"],\n", "        pwd=os.environ[\"PASSWORD\"],\n", "        course_id=course_id,\n", "        )"]}, {"cell_type": "markdown", "id": "326a41c8", "metadata": {}, "source": ["First, let us import the required libraries:"]}, {"cell_type": "code", "execution_count": null, "id": "0644c951", "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "import numpy as np\n", "from tqdm.notebook import tqdm\n", "import tensorflow as tf\n", "from tensorflow.keras.models import Model, Sequential\n", "from tensorflow.keras.layers import Dense, Input\n", "from tensorflow.keras.losses import BinaryCrossentropy, binary_crossentropy\n", "from tensorflow.keras.optimizers import Adam\n", "from sklearn.decomposition import PCA\n", "from sklearn.datasets import fetch_olivetti_faces\n", "from sklearn.preprocessing import StandardScaler\n", "from IPython.display import display"]}, {"cell_type": "markdown", "id": "bd539ff1", "metadata": {}, "source": ["In this lab, We'll use the Olivetti Faces dataset, which contains a dataset of `(64, 64)` gray scale images with different faces:"]}, {"cell_type": "code", "execution_count": null, "id": "235b919a", "metadata": {}, "outputs": [], "source": ["X, _ = fetch_olivetti_faces(return_X_y=True)"]}, {"cell_type": "markdown", "id": "dedca946", "metadata": {}, "source": ["Let's see some images of the dataset:"]}, {"cell_type": "code", "execution_count": null, "id": "efe2fb6e", "metadata": {}, "outputs": [], "source": ["fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n", "for i in range(3):\n", "    for j in range(3):\n", "        ax = axes[i, j]\n", "        idx = np.random.randint(X.shape[0])\n", "        ax.imshow(X[idx].reshape(64, 64), cmap=\"gray\")"]}, {"cell_type": "markdown", "id": "0e1c8747", "metadata": {}, "source": ["First, let us train a `PCA` model with the images:"]}, {"cell_type": "code", "execution_count": null, "id": "16f739f9", "metadata": {}, "outputs": [], "source": ["pca = PCA(n_components=128).fit(X)\n", "components = tf.constant(pca.components_)\n", "print(components.shape)"]}, {"cell_type": "markdown", "id": "dc7322f4", "metadata": {}, "source": ["This model can be seen as a classical autoencoder that encodes (`transform`) and decodes (`inverse_transform`), as follows:"]}, {"cell_type": "code", "execution_count": null, "id": "30f6e38e", "metadata": {}, "outputs": [], "source": ["X_t = pca.transform(X)\n", "print(X_t.shape)"]}, {"cell_type": "markdown", "id": "18872846", "metadata": {}, "source": ["Also, We can compute the reconstruction of the images:"]}, {"cell_type": "code", "execution_count": null, "id": "9e5561e5", "metadata": {}, "outputs": [], "source": ["X_r = pca.inverse_transform(X_t)\n", "print(X_r.shape)"]}, {"cell_type": "markdown", "id": "8586b980", "metadata": {}, "source": ["Let's see a comparison between the original images and the reconstruction:"]}, {"cell_type": "code", "execution_count": null, "id": "5adce2d1", "metadata": {}, "outputs": [], "source": ["fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n", "for i in range(5):\n", "    idx = np.random.randint(X.shape[0])\n", "    ax = axes[0, i]\n", "    ax.imshow(X[idx].reshape(64, 64), cmap=\"gray\")\n", "    ax = axes[1, i]\n", "    ax.imshow(X_r[idx].reshape(64, 64), cmap=\"gray\")\n", "\n", "axes[0, 0].set_ylabel(\"Original\")\n", "axes[1, 0].set_ylabel(\"Reconstruction\")\n", "fig.tight_layout()"]}, {"cell_type": "markdown", "id": "e0d9e49d", "metadata": {}, "source": ["Internally, the `PCA` model is doing the following operations:"]}, {"cell_type": "code", "execution_count": null, "id": "024470ec", "metadata": {}, "outputs": [], "source": ["# transform\n", "scaler = StandardScaler(with_std=False).fit(X)\n", "X_s = scaler.transform(X)\n", "X_t = X_s @ pca.components_.T # transform\n", "print(X_t.shape)"]}, {"cell_type": "code", "execution_count": null, "id": "a10f878e", "metadata": {}, "outputs": [], "source": ["# inverse transform\n", "X_r = X_t @ pca.components_\n", "X_r = scaler.inverse_transform(X_r)\n", "print(X_r.shape)"]}, {"cell_type": "markdown", "id": "24c05aa0", "metadata": {}, "source": ["Let's see that the results are equivalent:"]}, {"cell_type": "code", "execution_count": null, "id": "88055c43", "metadata": {}, "outputs": [], "source": ["fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n", "for i in range(5):\n", "    idx = np.random.randint(X.shape[0])\n", "    ax = axes[0, i]\n", "    ax.imshow(X[idx].reshape(64, 64), cmap=\"gray\")\n", "    ax = axes[1, i]\n", "    ax.imshow(X_r[idx].reshape(64, 64), cmap=\"gray\")\n", "\n", "axes[0, 0].set_ylabel(\"Original\")\n", "axes[1, 0].set_ylabel(\"Reconstruction\")\n", "fig.tight_layout()"]}, {"cell_type": "code", "execution_count": null, "id": "34292b18", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["fig.show()"]}, {"cell_type": "markdown", "id": "3bf18484", "metadata": {}, "source": ["## Task 1\n", "\n", "In this task, you must fit a decoder model for a variational autoencoder that replicates the `PCA` model, specifically, you have the following model:\n", "\n", "$$\n", "\\mu = \\mathbf{x} \\cdot \\mathbf{W} ^ T\\\\\n", "\\mathbf{z} \\sim \\mathcal{N}(\\mu, 1)\\\\\n", "\\tilde{\\mathbf{x}} = \\text{decoder}(\\mathbf{z})\n", "$$\n", "\n", "Where $\\mathbf{x}$ is an input image, $\\mathbf{W}$ are the `PCA` components, $\\mu$ is the VAE's mean (in this case, the `PCA` transformation), $\\mathbf{z}$ is the sample from the latent distribution and $\\tilde{\\mathbf{x}}$ is the reconstruction.\n", "\n", "You must implement the following methods:\n", "\n", "* `encode`: this method must compute $\\mu$ from $\\mathbf{x}$ and $\\mathbf{W}$.\n", "* `reparameterize`: this method must compute $\\mathbf{z}$ from $\\mu$.\n", "* `decode`: this method must compute the reconstruction $\\tilde{\\mathbf{x}}$ from $\\mathbf{z}$."]}, {"cell_type": "code", "execution_count": null, "id": "0dd1aa84", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["def variable_decoder(pca_components):\n", "    class VariableDecoder(Model):\n", "        def __init__(self, pca_components, *args, **kwargs):\n", "            super(VariableDecoder, self).__init__(*args, **kwargs)\n", "            self.components = pca_components\n", "            self.decoder = Sequential([\n", "                Input(shape=(pca_components.shape[0],)),\n", "                Dense(\n", "                    pca_components.shape[1], activation=\"sigmoid\",\n", "                    use_bias = False\n", "                    )\n", "                ])\n", "\n", "        def encode(self, x):\n", "            # YOUR CODE HERE\n", "            ...\n", "\n", "        def reparameterize(self, mean):\n", "            # YOUR CODE HERE\n", "            ...\n", "\n", "        def decode(self, z):\n", "            # YOUR CODE HERE\n", "            ...\n", "            \n", "        def call(self, x):\n", "            mu = self.encode(x)\n", "            z = self.reparameterize(mu)\n", "            x_rec = self.decoder(z)\n", "            return x_rec\n", "\n", "    return VariableDecoder(pca_components)"]}, {"cell_type": "markdown", "id": "fc62fcf4", "metadata": {}, "source": ["Let's validate the model with a simple test case:"]}, {"cell_type": "code", "execution_count": null, "id": "781d832e", "metadata": {}, "outputs": [], "source": ["components = tf.constant([\n", "    [1.0, 1.5],\n", "    [-2.3, 4.5],\n", "    [6.4, 3.2]\n", "])\n", "X = tf.constant([\n", "    [2.3, -1.2],\n", "    [3.6, 4.2],\n", "    [1.1, 0.2]\n", "])\n", "m1 = variable_decoder(components)\n", "m1.decoder.layers[-1].set_weights((components, ))\n", "m1.build(X.shape)\n", "m1.summary()"]}, {"cell_type": "markdown", "id": "e64a911e", "metadata": {}, "source": ["The output of the following cell must be:\n", "\n", "```python\n", "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n", "array([[  0.49999988, -10.690001  ,  10.88      ],\n", "       [  9.9       ,  10.62      ,  36.48      ],\n", "       [  1.4000001 ,  -1.6299999 ,   7.6800003 ]], dtype=float32)>\n", "```"]}, {"cell_type": "code", "execution_count": null, "id": "848c71b2", "metadata": {}, "outputs": [], "source": ["mu = m1.encode(X)\n", "display(mu)"]}, {"cell_type": "markdown", "id": "96f35adc", "metadata": {}, "source": ["The output of the following cell must contain values **similar** (depends on sampling) to:\n", "\n", "```python\n", "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n", "array([[ -0.30128342, -10.981316  ,  10.142529  ],\n", "       [  8.948406  ,  10.770711  ,  35.61869   ],\n", "       [  2.1709187 ,  -3.2726154 ,   7.2098346 ]], dtype=float32)>\n", "```"]}, {"cell_type": "code", "execution_count": null, "id": "c0e0da94", "metadata": {}, "outputs": [], "source": ["z = m1.reparameterize(mu)\n", "display(z)"]}, {"cell_type": "markdown", "id": "1be68d04", "metadata": {}, "source": ["The output of the following cell must be:\n", "\n", "```python\n", "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n", "array([[1.0000000e+00, 3.5840928e-06],\n", "       [1.0000000e+00, 1.0000000e+00],\n", "       [1.0000000e+00, 1.0000000e+00]], dtype=float32)>\n", "```"]}, {"cell_type": "code", "execution_count": null, "id": "379d3709", "metadata": {}, "outputs": [], "source": ["display(m1.decode(mu))"]}, {"cell_type": "markdown", "id": "c325bb1f", "metadata": {}, "source": ["Model definition:"]}, {"cell_type": "code", "execution_count": null, "id": "29ef066b", "metadata": {}, "outputs": [], "source": ["m1 = variable_decoder(pca.components_)\n", "m1.build(X.shape)\n", "m1.summary()"]}, {"cell_type": "markdown", "id": "4a4b9afd", "metadata": {}, "source": ["Let's compile the model using the binary cross-entropy loss:"]}, {"cell_type": "code", "execution_count": null, "id": "ecfb9737", "metadata": {}, "outputs": [], "source": ["m1.compile(\n", "        loss=BinaryCrossentropy(),\n", "        optimizer=Adam(learning_rate=1e-2)\n", "        )"]}, {"cell_type": "markdown", "id": "e55f1d7a", "metadata": {}, "source": ["We can train the model:"]}, {"cell_type": "code", "execution_count": null, "id": "cfd0d29d", "metadata": {}, "outputs": [], "source": ["norm = StandardScaler(with_std = False)\n", "X_s = norm.fit_transform(X)\n", "m1.fit(X_s, X_s, epochs=100, batch_size=400)"]}, {"cell_type": "markdown", "id": "f51aba54", "metadata": {}, "source": ["Now, We can generate random images using the trained model, for this, we compute the mean of the latent representations and use this to generate random vectors:"]}, {"cell_type": "code", "execution_count": null, "id": "2e9c0324", "metadata": {}, "outputs": [], "source": ["mu = tf.reduce_mean(X_s @ tf.transpose(components), axis=0)\n", "random_vectors = tf.random.normal(\n", "        mean=mu, stddev=1., shape=(9, components.shape[0])\n", "        )\n", "rec_imgs = norm.inverse_transform(\n", "        m1\n", "        .decoder(random_vectors)\n", "        .numpy()\n", "        .reshape(9, -1)\n", "        )"]}, {"cell_type": "markdown", "id": "e7643d5e", "metadata": {}, "source": ["We can visualize the generated images:"]}, {"cell_type": "code", "execution_count": null, "id": "96e38fd0", "metadata": {}, "outputs": [], "source": ["fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n", "cont = 0\n", "for i in range(3):\n", "    for j in range(3):\n", "        ax = axes[i, j]\n", "        ax.imshow(rec_imgs[cont].reshape(64, 64), cmap=\"gray\")\n", "        ax.axis(\"off\")\n", "        cont += 1"]}, {"cell_type": "markdown", "id": "339d4b4e", "metadata": {}, "source": ["The output of the last cell must be similar to the following image:\n", "\n", "<img src=\"local/imgs/pca_faces1.png\" width=\"60%\">"]}, {"cell_type": "code", "execution_count": null, "id": "153aff36", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["def grader1(functions, variables, caller_userid):\n", "    import numpy as np\n", "    import tensorflow as tf\n", "    from tensorflow.keras.models import Model, Sequential\n", "    from tensorflow.keras.layers import Dense, Input\n", "\n", "    namespace = locals()\n", "    for f in functions.values():\n", "        exec(f, namespace)\n", "    variable_decoder = namespace[\"variable_decoder\"]\n", "    msg = \"Testing your code with 10 random cases.</br>\"\n", "\n", "    for _ in range(10):\n", "        x = tf.random.normal(shape=(10_000, 2))\n", "        components = tf.random.normal(shape=(2, 2))\n", "        model = variable_decoder(components)\n", "\n", "        encoded = model.encode(x)\n", "\n", "        if not isinstance(encoded, tf.Tensor):\n", "            msg += f\"<b>Your encode method must return a tensorflow's tensor.</b></br>\"\n", "            return 0, msg\n", "\n", "        encoded = encoded.numpy()\n", "        encoded_teacher = (x @ tf.transpose(components)).numpy()\n", "\n", "        if not np.allclose(encoded, encoded_teacher):\n", "            msg += f\"<b>Wrong encode method.</b></br>\"\n", "            return 0, msg\n", "\n", "        z = model.reparameterize(encoded)\n", "\n", "        if not isinstance(z, tf.Tensor):\n", "            msg += f\"<b>Your reparameterize method must return a tensorflow's tensor.</b></br>\"\n", "            return 0, msg\n", "\n", "        sample = tf.random.normal(mean=0., stddev=1., shape=encoded.shape)\n", "        z_teacher = sample + encoded\n", "\n", "        z = z.numpy()\n", "        z_teacher = z_teacher.numpy()\n", "\n", "        if not np.allclose(z.mean(axis=0), z_teacher.mean(axis=0), atol=0.5):\n", "            msg += f\"<b>Wrong reparameterize method.</b></br>\"\n", "            return 0, msg\n", "\n", "        decode = model.decode(z)\n", "\n", "        if not isinstance(decode, tf.Tensor):\n", "            msg += f\"<b>Your reparameterize method must return a tensorflow's tensor.</b></br>\"\n", "            return 0, msg\n", "\n", "        decode = decode.numpy()\n", "        decode_teacher = model.decoder(z).numpy()\n", "\n", "        if not np.allclose(decode, decode_teacher):\n", "            msg += f\"<b>Wrong decode method.</b></br>\"\n", "            return 0, msg\n", "        \n", "    return 5, msg + \"<b>Success!</b>\""]}, {"cell_type": "markdown", "id": "7c6e7e9b", "metadata": {}, "source": ["Use the following cell to grade your code:"]}, {"cell_type": "code", "execution_count": null, "id": "bb9a8852", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["student.submit_task(namespace=globals(), task_id=\"T1\");"]}, {"cell_type": "markdown", "id": "549b0702", "metadata": {}, "source": ["## Task 2\n", "\n", "In this task, you must fit an encoder model for a variational autoencoder that replicates the `PCA` model, specifically, you have the following model:\n", "\n", "$$\n", "\\mu, \\log{(\\sigma ^ 2)} = \\text{encoder}(\\mathbf{x})\\\\\n", "\\mathbf{z} \\sim \\mathcal{N}(\\mu, \\sigma)\\\\\n", "\\tilde{\\mathbf{x}} = \\mathbf{z} \\cdot \\mathbf{W}\n", "$$\n", "\n", "Where $\\mathbf{x}$ is an input image, $\\mathbf{W}$ are the `PCA` components, $\\mu$ is the VAE's mean, $\\sigma$ is the VAE's standard deviation, $\\mathbf{z}$ is the sample from the latent distribution and $\\tilde{\\mathbf{x}}$ is the reconstruction.\n", "\n", "You must implement the following methods:\n", "\n", "* `encode`: this method must compute $\\mu$ and $\\log{(\\sigma) ^ 2}$ using the encoder.\n", "* `reparameterize`: this method must compute $\\mathbf{z}$ from $\\mu$ and $\\log{(\\sigma ^ 2)}$.\n", "* `decode`: this method must compute the reconstruction $\\tilde{\\mathbf{x}}$ from $\\mathbf{z}$ using $\\mathbf{W}$ (you must apply a sigmoid function to the decoder's output to keep the data in the range $[0, 1]$)."]}, {"cell_type": "code", "execution_count": null, "id": "e31820de", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["def variable_encoder(components):\n", "    class VariableEncoder(Model):\n", "        def __init__(self, components, *args, **kwargs):\n", "            super(VariableEncoder, self).__init__(*args, **kwargs)\n", "            self.encoder = Sequential([\n", "                Input(shape=(components.shape[1],)),\n", "                Dense(\n", "                    components.shape[0] * 2, activation=\"linear\",\n", "                    use_bias = False\n", "                    )\n", "                ])\n", "            self.components = components\n", "\n", "        def encode(self, x):\n", "            #YOUR CODE HERE\n", "            ...\n", "\n", "        def reparameterize(self, mu, log_var):\n", "            #YOUR CODE HERE\n", "            ...\n", "\n", "        def decode(self, z):\n", "            #YOUR CODE HERE\n", "            ...\n", "            \n", "        @tf.function\n", "        def call(self, x):\n", "            mu, log_var = self.encode(x)\n", "            z = self.reparameterize(mu, log_var)\n", "            x_rec = self.decode(z)\n", "            return x_rec\n", "    return VariableEncoder(components)"]}, {"cell_type": "markdown", "id": "0f02a29c", "metadata": {}, "source": ["Let's validate the model with a simple test case:"]}, {"cell_type": "code", "execution_count": null, "id": "be4e41f2", "metadata": {}, "outputs": [], "source": ["components = tf.constant([\n", "    [1.0, 1.5],\n", "    [-2.3, 4.5],\n", "    [6.4, 3.2]\n", "])\n", "X = tf.constant([\n", "    [2.3, -1.2],\n", "    [3.6, 4.2],\n", "    [1.1, 0.2]\n", "])\n", "m2 = variable_encoder(components)\n", "m2.encoder.layers[-1].set_weights((tf.concat([tf.transpose(components)] * 2, axis=1), ))\n", "m2.build(X.shape)\n", "m2.summary()"]}, {"cell_type": "markdown", "id": "d0fa742a", "metadata": {}, "source": ["The output of the following cell must be:\n", "\n", "```python\n", "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n", "array([[  0.49999988, -10.690001  ,  10.88      ],\n", "       [  9.9       ,  10.62      ,  36.48      ],\n", "       [  1.4000001 ,  -1.6299999 ,   7.6800003 ]], dtype=float32)>\n", "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n", "array([[  0.49999988, -10.690001  ,  10.88      ],\n", "       [  9.9       ,  10.62      ,  36.48      ],\n", "       [  1.4000001 ,  -1.6299999 ,   7.6800003 ]], dtype=float32)>\n", "```"]}, {"cell_type": "code", "execution_count": null, "id": "c1d4fa70", "metadata": {}, "outputs": [], "source": ["mu, logvar = m2.encode(X)\n", "display(mu)\n", "display(logvar)"]}, {"cell_type": "markdown", "id": "21f8433f", "metadata": {}, "source": ["The output of the following cell must contain values similar (depends on sampling) to:\n", "\n", "```python\n", "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n", "array([[ 2.3777792e+00, -1.0683963e+01,  1.4963301e+02],\n", "       [ 2.2756420e+01,  1.2129482e+02, -4.9136872e+07],\n", "       [ 1.9654572e-01, -1.8794684e+00, -7.5251245e+00]], dtype=float32)>\n", "```"]}, {"cell_type": "code", "execution_count": null, "id": "21097e67", "metadata": {}, "outputs": [], "source": ["z = m2.reparameterize(mu, logvar)\n", "display(z)"]}, {"cell_type": "markdown", "id": "cba663eb", "metadata": {}, "source": ["The output of the following cell must be:\n", "\n", "```python\n", "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n", "array([[1.0000000e+00, 3.5840928e-06],\n", "       [1.0000000e+00, 1.0000000e+00],\n", "       [1.0000000e+00, 1.0000000e+00]], dtype=float32)>\n", "```"]}, {"cell_type": "code", "execution_count": null, "id": "36beb9fc", "metadata": {}, "outputs": [], "source": ["display(m2.decode(mu))"]}, {"cell_type": "markdown", "id": "a238dc11", "metadata": {}, "source": ["Model definition:"]}, {"cell_type": "code", "execution_count": null, "id": "e319eaa0", "metadata": {}, "outputs": [], "source": ["m2 = variable_encoder(components)\n", "m2.build(X.shape)\n", "m2.summary()"]}, {"cell_type": "markdown", "id": "a5d04f2e", "metadata": {}, "source": ["Let's compile the model using the binary cross-entropy loss:"]}, {"cell_type": "code", "execution_count": null, "id": "480aea56", "metadata": {}, "outputs": [], "source": ["m2.compile(\n", "        loss=BinaryCrossentropy(),\n", "        optimizer=Adam(learning_rate=1e-3)\n", "        )"]}, {"cell_type": "markdown", "id": "256e6f54", "metadata": {}, "source": ["We can train the model:"]}, {"cell_type": "code", "execution_count": null, "id": "68107385", "metadata": {}, "outputs": [], "source": ["norm = StandardScaler(with_std = False)\n", "X_s = norm.fit_transform(X)\n", "m2.fit(X_s, X_s, epochs=100, batch_size=400)"]}, {"cell_type": "markdown", "id": "e6650b57", "metadata": {}, "source": ["Now, We can generate some images that are similar to a given image (in this case, the first image):"]}, {"cell_type": "code", "execution_count": null, "id": "7c42bddc", "metadata": {}, "outputs": [], "source": ["x_test = X_s[:1]\n", "X_test = tf.concat([x_test] * 9, axis=0)\n", "x_rec = m2(X_test)\n", "rec_imgs = norm.inverse_transform(\n", "        x_rec\n", "        .numpy()\n", "        .reshape(9, -1)\n", "        )"]}, {"cell_type": "markdown", "id": "6b8b43a1", "metadata": {}, "source": ["Let's visualize them:"]}, {"cell_type": "code", "execution_count": null, "id": "b194bcaf", "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots()\n", "ax.imshow(tf.reshape(X[:1], (64, 64)), cmap=\"gray\")\n", "ax.axis(\"off\")\n", "ax.set_title(\"Original Image\")"]}, {"cell_type": "code", "execution_count": null, "id": "68be199d", "metadata": {}, "outputs": [], "source": ["fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n", "cont = 0\n", "for i in range(3):\n", "    for j in range(3):\n", "        ax = axes[i, j]\n", "        ax.imshow(rec_imgs[cont].reshape(64, 64), cmap=\"gray\")\n", "        ax.axis(\"off\")\n", "        cont += 1"]}, {"cell_type": "markdown", "id": "e8a6356d", "metadata": {}, "source": ["The last output cell must be similar to the following image:\n", "\n", "<img src=\"local/imgs/pca_faces2.png\" width=\"60%\">"]}, {"cell_type": "code", "execution_count": null, "id": "a7f4b5c4", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["def grader2(functions, variables, caller_userid):\n", "    import numpy as np\n", "    import tensorflow as tf\n", "    from tensorflow.keras.models import Model, Sequential\n", "    from tensorflow.keras.layers import Dense, Input\n", "\n", "    namespace = locals()\n", "    for f in functions.values():\n", "        exec(f, namespace)\n", "    variable_encoder = namespace[\"variable_encoder\"]\n", "    msg = \"Testing your code with 10 random cases.</br>\"\n", "\n", "    for _ in range(10):\n", "        x = tf.random.normal(shape=(10_000, 2))\n", "        components = tf.random.normal(shape=(2, 2))\n", "        model = variable_encoder(components)\n", "\n", "        mu, log_var = model.encode(x)\n", "\n", "        if not isinstance(mu, tf.Tensor):\n", "            msg += f\"<b>Your encode method must return a tuple of tensorflow's tensors.</b></br>\"\n", "            return 0, msg\n", "\n", "        if not isinstance(log_var, tf.Tensor):\n", "            msg += f\"<b>Your encode method must return a tuple of tensorflow's tensors.</b></br>\"\n", "            return 0, msg\n", "\n", "        params = model.encoder(x)\n", "        mu_teacher, log_var_teacher = tf.split(\n", "                params, num_or_size_splits=2, axis=1\n", "                )\n", "\n", "        mu_student = mu.numpy()\n", "        log_var_student = log_var.numpy()\n", "        mu_teacher = mu_teacher.numpy()\n", "        log_var_teacher = log_var_teacher.numpy()\n", "\n", "        if not np.allclose(mu_student, mu_teacher):\n", "            msg += f\"<b>Wrong mu parameter in the encoder method.</b></br>\"\n", "            return 0, msg\n", "        if not np.allclose(log_var_student, log_var_teacher):\n", "            msg += f\"<b>Wrong log_var parameter en the encoder method.</b></br>\"\n", "            return 0, msg\n", "\n", "        z = model.reparameterize(mu, log_var)\n", "\n", "        if not isinstance(z, tf.Tensor):\n", "            msg += f\"<b>Your reparameterize method must return a tensorflow's tensor.</b></br>\"\n", "            return 0, msg\n", "\n", "        sample = tf.random.normal(mean=0., stddev=1., shape=mu.shape)\n", "        z_teacher = sample * tf.exp(log_var * .5) + mu\n", "\n", "        z = z.numpy()\n", "        z_teacher = z_teacher.numpy()\n", "\n", "        if not np.allclose(z.mean(axis=0), z_teacher.mean(axis=0), atol=0.5):\n", "            msg += f\"<b>Wrong reparameterize method.</b></br>\"\n", "            return 0, msg\n", "\n", "        decode = model.decode(z)\n", "\n", "        if not isinstance(decode, tf.Tensor):\n", "            msg += f\"<b>Your reparameterize method must return a tensorflow's tensor.</b></br>\"\n", "            return 0, msg\n", "\n", "        decode = decode.numpy()\n", "        decode_teacher = tf.sigmoid(z @ components).numpy()\n", "\n", "        if not np.allclose(decode, decode_teacher):\n", "            msg += f\"<b>Wrong decode method.</b></br>\"\n", "            return 0, msg\n", "        \n", "    return 5, msg + \"<b>Success!</b>\""]}, {"cell_type": "markdown", "id": "147e781e", "metadata": {}, "source": ["Use the following cell to grade your code:"]}, {"cell_type": "code", "execution_count": null, "id": "cee7a926", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["student.submit_task(namespace=globals(), task_id=\"T2\");"]}, {"cell_type": "markdown", "id": "0f63c8d8", "metadata": {}, "source": ["## Task 3\n", "\n", "In this task you must implement the full VAE model which must perform the following operations:\n", "\n", "$$\n", "\\mu, \\sigma = \\text{encoder}(\\mathbf{x})\\\\\n", "\\mathbf{z} \\sim \\mathcal{N}(\\mu, \\sigma)\\\\\n", "\\tilde{\\mathbf{x}} = \\text{decoder}(\\mathbf{z})\n", "$$\n", "\n", "Where $\\mathbf{x}$ is an input image, $\\mu$ is the VAE's mean, $\\sigma$ is the VAE's standard deviation, $\\mathbf{z}$ is the sample from the latent distribution and $\\tilde{\\mathbf{x}}$ is the reconstruction.\n", "\n", "You must implement the following methods:\n", "\n", "* `encode`: this method must compute $\\mu$ and $\\log{(\\sigma) ^ 2}$ using the encoder.\n", "* `reparameterize`: this method must compute $\\mathbf{z}$ from $\\mu$ and $\\log{(\\sigma ^ 2)}$.\n", "* `decode`: this method must compute the reconstruction $\\tilde{\\mathbf{x}}$ from $\\mathbf{z}$."]}, {"cell_type": "code", "execution_count": null, "id": "d01d3816", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["def vae(n_components, input_size):\n", "    class Vae(Model):\n", "        def __init__(self, n_components, input_size, *args, **kwargs):\n", "            super(Vae, self).__init__(*args, **kwargs)\n", "            self.encoder = Sequential([\n", "                Input(shape=(input_size, )),\n", "                Dense(\n", "                    256, activation=\"relu\"\n", "                    ),\n", "                Dense(\n", "                    128, activation=\"relu\"\n", "                    ),\n", "                Dense(\n", "                    n_components * 2, activation=\"linear\",\n", "                    use_bias = False\n", "                    )\n", "                ])\n", "            self.decoder = Sequential([\n", "                Input(shape=(n_components, )),\n", "                Dense(\n", "                    128, activation=\"relu\"\n", "                    ),\n", "                Dense(\n", "                    256, activation=\"relu\"\n", "                    ),\n", "                Dense(\n", "                    input_size, activation=\"sigmoid\",\n", "                    use_bias = False\n", "                    )\n", "                ])\n", "\n", "        def encode(self, x):\n", "            # YOUR CODE HERE\n", "            ...\n", "\n", "        def reparameterize(self, mu, log_var):\n", "            # YOUR CODE HERE\n", "            ...\n", "\n", "        def decode(self, z):\n", "            # YOUR CODE HERE\n", "            ...\n", "\n", "        @tf.function\n", "        def call(self, x):\n", "            mu, log_var = self.encode(x)\n", "            z = self.reparameterize(mu, log_var)\n", "            x_rec = self.decode(z)\n", "            return x_rec, z, mu, log_var\n", "\n", "    return Vae(n_components, input_size)"]}, {"cell_type": "markdown", "id": "3e0e0ab1", "metadata": {}, "source": ["Let's validate the model with a simple test case:"]}, {"cell_type": "code", "execution_count": null, "id": "0c1a47dd", "metadata": {}, "outputs": [], "source": ["X = tf.constant([\n", "    [2.3, -1.2],\n", "    [3.6, 4.2],\n", "    [1.1, 0.2]\n", "])\n", "m3 = vae(n_components=2, input_size=2)\n", "np.random.seed(0)\n", "for layer in m3.encoder.layers[1:]:\n", "    weights = layer.get_weights()\n", "    new_weights = [np.random.normal(size = weight.shape) for weight in weights]\n", "    layer.set_weights(new_weights)\n", "for layer in m3.decoder.layers[1:]:\n", "    weights = layer.get_weights()\n", "    new_weights = [np.random.normal(size = weight.shape) for weight in weights]\n", "    layer.set_weights(new_weights)\n", "m3.build(X.shape)\n", "m3.summary()"]}, {"cell_type": "markdown", "id": "d21e1b0f", "metadata": {}, "source": ["The output of the following cell must be:\n", "\n", "```python\n", "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n", "array([[  -4.7670307,  -32.039318 ],\n", "       [ -37.146942 , -108.32607  ],\n", "       [  -6.7786207,  -27.726944 ]], dtype=float32)>\n", "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n", "array([[36.52964   ,  7.2877674 ],\n", "       [94.258766  , 47.306343  ],\n", "       [21.852629  , -0.47683525]], dtype=float32)>\n", "```"]}, {"cell_type": "code", "execution_count": null, "id": "31fb7370", "metadata": {}, "outputs": [], "source": ["mu, logvar = m3.encode(X)\n", "display(mu)\n", "display(logvar)"]}, {"cell_type": "markdown", "id": "1e8cef92", "metadata": {}, "source": ["The output of the following cell must be **similar** (depends on sampling) to:\n", "\n", "```python\n", "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n", "array([[ 1.2691664e+08, -8.6150879e+01],\n", "       [-4.3849702e+19,  1.5783530e+10],\n", "       [-2.9923719e+04, -2.8367697e+01]], dtype=float32)>\n", "```"]}, {"cell_type": "code", "execution_count": null, "id": "fc5ba87b", "metadata": {}, "outputs": [], "source": ["z = m3.reparameterize(mu, logvar)\n", "display(z)"]}, {"cell_type": "markdown", "id": "b002c173", "metadata": {}, "source": ["The output of the following cell must be:\n", "\n", "```python\n", "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n", "array([[1., 0.],\n", "       [1., 0.],\n", "       [1., 0.]], dtype=float32)>\n", "```"]}, {"cell_type": "code", "execution_count": null, "id": "8b54cd23", "metadata": {}, "outputs": [], "source": ["display(m3.decode(mu))"]}, {"cell_type": "markdown", "id": "74871bc8", "metadata": {}, "source": ["Model definition:"]}, {"cell_type": "code", "execution_count": null, "id": "d4b1dfe3", "metadata": {}, "outputs": [], "source": ["m3 = vae(n_components = 128, input_size = X.shape[1])\n", "m3.build(X.shape)\n", "m3.summary()"]}, {"cell_type": "markdown", "id": "784ac930", "metadata": {}, "source": ["We can train this model using the binary cross-entropy loss:"]}, {"cell_type": "code", "execution_count": null, "id": "e47d0541", "metadata": {}, "outputs": [], "source": ["vae_loss = BinaryCrossentropy()\n", "optimizer = Adam(learning_rate=1e-3)"]}, {"cell_type": "markdown", "id": "83c05efb", "metadata": {}, "source": ["We can train the model:"]}, {"cell_type": "code", "execution_count": null, "id": "d2fee347", "metadata": {}, "outputs": [], "source": ["norm = StandardScaler(with_std = False)\n", "X_s = norm.fit_transform(X)\n", "X_s = tf.constant(X_s)\n", "optimizer = Adam(learning_rate = 1e-4)\n", "for epoch in tqdm(range(100)):\n", "    with tf.GradientTape() as t:\n", "        x_rec, z, mu, log_var = m3(X_s)\n", "        loss = vae_loss(X_s, x_rec)\n", "        grads = t.gradient(loss, m3.trainable_variables)\n", "        optimizer.apply_gradients(zip(grads, m3.trainable_variables))"]}, {"cell_type": "markdown", "id": "40d0d02b", "metadata": {}, "source": ["Now, We can generate random images using the trained model, for this, we generate random normal vectors:"]}, {"cell_type": "code", "execution_count": null, "id": "c7c7288d", "metadata": {}, "outputs": [], "source": ["random_vectors = tf.random.normal(\n", "        mean=0, stddev=1., shape=(9, 128)\n", "        )\n", "rec_imgs = norm.inverse_transform(\n", "        m3.decode(random_vectors)\n", "        )"]}, {"cell_type": "markdown", "id": "d1fdfda0", "metadata": {}, "source": ["We can visualize the generated images:"]}, {"cell_type": "code", "execution_count": null, "id": "e25f3258", "metadata": {}, "outputs": [], "source": ["fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n", "cont = 0\n", "for i in range(3):\n", "    for j in range(3):\n", "        ax = axes[i, j]\n", "        ax.imshow(rec_imgs[cont].reshape(64, 64), cmap=\"gray\")\n", "        ax.axis(\"off\")\n", "        cont += 1"]}, {"cell_type": "markdown", "id": "78e98834", "metadata": {}, "source": ["As you can see, the results are too noisy and the generated faces are too similar. This is because We're not using the proper loss function. The last cell must output a figure similar to this one:\n", "\n", "<img src=\"local/imgs/pca_faces3.png\" width=\"60%\">"]}, {"cell_type": "markdown", "id": "c54a56a0", "metadata": {}, "source": ["Use the following cell to grade your code:"]}, {"cell_type": "code", "execution_count": null, "id": "054ad730", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["student.submit_task(namespace=globals(), task_id=\"T3\");"]}, {"cell_type": "markdown", "id": "c57e19f8", "metadata": {}, "source": ["## Task 4\n", "\n", "In this task you must implement the loss function for a VAE:\n", "\n", "$$\n", "\\mathcal{L}= \\mathcal{L}_1 + \\mathcal{L}_2\\\\\n", "\\mathcal{L}_1 = \\text{binary_crossentropy}(\\mathbf{x}, \\tilde{\\mathbf{x}})\\\\\n", "\\mathcal{L}_2 = \\text{KL}(\\mathcal{N}(\\mu, \\sigma)|| \\mathcal{N}(0, I))\n", "$$\n", "\n", "You can use the following implementation of the normal's pdf function that uses $\\log{(\\sigma ^ 2)}$ (`logvar`) as parameter:"]}, {"cell_type": "code", "execution_count": null, "id": "63948cad", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["@tf.function\n", "def log_normal_pdf(sample, mu, logvar):\n", "    log2pi = tf.math.log(2. * np.pi)\n", "    return tf.reduce_sum(\n", "        -.5 * ((sample - mu) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n", "        axis=1\n", "        )"]}, {"cell_type": "markdown", "id": "1486e08c", "metadata": {}, "source": ["You must implement the `vae_loss` function, which has the following parameters:\n", "\n", "`x`: batch of images.\n", "`x_rec`: reconstruction of the images.\n", "`z`: latent sample.\n", "`mu`: encoded mean.\n", "`log_var`: encoded log-variance."]}, {"cell_type": "code", "execution_count": null, "id": "4274c178", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["@tf.function\n", "def vae_loss(x, x_rec, z, mu, log_var):\n", "    logits = binary_crossentropy(x, x_rec)\n", "    logpx_z = tf.reduce_mean(logits)\n", "    logpz = log_normal_pdf(z, 0., 0.)\n", "    logqz_x = log_normal_pdf(z, mu, log_var)\n", "    return - tf.reduce_mean(logpx_z + logpz - logqz_x)"]}, {"cell_type": "markdown", "id": "92376ff9", "metadata": {}, "source": ["We can train a new VAE using this loss function:"]}, {"cell_type": "code", "execution_count": null, "id": "aec7effd", "metadata": {}, "outputs": [], "source": ["optimizer = Adam(learning_rate=1e-3)"]}, {"cell_type": "markdown", "id": "9f884227", "metadata": {}, "source": ["Model definition:"]}, {"cell_type": "code", "execution_count": null, "id": "5adc84fd", "metadata": {}, "outputs": [], "source": ["m4 = vae(n_components = 128, input_size = X.shape[1])\n", "m4.build(X.shape)\n", "m4.summary()"]}, {"cell_type": "markdown", "id": "131fe959", "metadata": {}, "source": ["We can train the model:"]}, {"cell_type": "code", "execution_count": null, "id": "1e475f4d", "metadata": {}, "outputs": [], "source": ["norm = StandardScaler(with_std = False)\n", "X_s = norm.fit_transform(X)\n", "X_s = tf.constant(X_s)\n", "optimizer = Adam(learning_rate = 1e-4)\n", "for epoch in tqdm(range(100)):\n", "    with tf.GradientTape() as t:\n", "        x_rec, z, mu, log_var = m4(X_s)\n", "        loss = vae_loss(X_s, x_rec, z, mu, log_var)\n", "        grads = t.gradient(loss, m4.trainable_variables)\n", "        optimizer.apply_gradients(zip(grads, m4.trainable_variables))"]}, {"cell_type": "markdown", "id": "f8ba8023", "metadata": {}, "source": ["Now, We can generate random images using the trained model, for this, we generate random normal vectors:"]}, {"cell_type": "code", "execution_count": null, "id": "e99e2f8b", "metadata": {}, "outputs": [], "source": ["random_vectors = tf.random.normal(\n", "        mean=0, stddev=1., shape=(9, 128)\n", "        )\n", "rec_imgs = norm.inverse_transform(\n", "        m4.decode(random_vectors)\n", "        )"]}, {"cell_type": "markdown", "id": "14abcfb2", "metadata": {}, "source": ["We can visualize the generated images:"]}, {"cell_type": "code", "execution_count": null, "id": "6f21fbd1", "metadata": {}, "outputs": [], "source": ["fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n", "cont = 0\n", "for i in range(3):\n", "    for j in range(3):\n", "        ax = axes[i, j]\n", "        ax.imshow(rec_imgs[cont].reshape(64, 64), cmap=\"gray\")\n", "        ax.axis(\"off\")\n", "        cont += 1"]}, {"cell_type": "markdown", "id": "952dd185", "metadata": {}, "source": ["The output of the last cell must be similar to the following image:\n", "\n", "<img src=\"local/imgs/pca_faces4.png\" width=\"60%\">"]}, {"cell_type": "code", "execution_count": null, "id": "a3771ad1", "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["def grader4(functions, variables, caller_userid):\n", "    import numpy as np\n", "    import tensorflow as tf\n", "    from tensorflow.keras.models import Model, Sequential\n", "    from tensorflow.keras.layers import Dense, Input\n", "    from tensorflow.keras.losses import BinaryCrossentropy, binary_crossentropy\n", "\n", "    @tf.function\n", "    def log_normal_pdf(sample, mu, logvar):\n", "        log2pi = tf.math.log(2. * np.pi)\n", "        return tf.reduce_sum(\n", "            -.5 * ((sample - mu) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n", "            axis=1\n", "            )\n", "\n", "    namespace = locals()\n", "    for f in functions.values():\n", "        exec(f, namespace)\n", "    vae_loss = namespace[\"vae_loss\"]\n", "    msg = \"Testing your code with 10 random cases.</br>\"\n", "\n", "    @tf.function\n", "    def vae_loss_teacher(x, x_rec, z, mu, log_var):\n", "        logits = binary_crossentropy(x, x_rec)\n", "        logpx_z = tf.reduce_mean(logits)\n", "        logpz = log_normal_pdf(z, 0., 0.)\n", "        logqz_x = log_normal_pdf(z, mu, log_var)\n", "        return - tf.reduce_mean(logpx_z + logpz - logqz_x)\n", "\n", "    for _ in range(10):\n", "        x = tf.random.normal(shape=(10_000, 10))\n", "        x_rec = tf.random.normal(shape=(10_000, 10))\n", "        z = tf.random.normal(shape=(10_000, 2))\n", "        mu = tf.random.normal(shape=(10_000, 2))\n", "        log_var = tf.random.normal(shape=(10_000, 2))\n", "\n", "        loss_student = vae_loss(x, x_rec, z, mu, log_var)\n", "\n", "        if not isinstance(loss_student, tf.Tensor):\n", "            msg += f\"<b>Your loss function must return a tensorflow's tensor.</b></br>\"\n", "            return 0, msg\n", "\n", "        loss_student = loss_student.numpy()\n", "        loss_teacher = vae_loss_teacher(x, x_rec, z, mu, log_var).numpy()\n", "\n", "        if not np.allclose(loss_student, loss_teacher):\n", "            msg += f\"<b>Wrong result.</b></br>\"\n", "            return 0, msg\n", "        \n", "    return 5, msg + \"<b>Success!</b>\""]}, {"cell_type": "markdown", "id": "a440ccc7", "metadata": {}, "source": ["Use the following cell to grade your code:"]}, {"cell_type": "code", "execution_count": null, "id": "1eb9ae47", "metadata": {}, "outputs": [], "source": ["student.submit_task(namespace=globals(), task_id=\"T4\");"]}], "metadata": {"jupytext": {"cell_metadata_filter": "-all", "main_language": "python", "notebook_metadata_filter": "-all"}}, "nbformat": 4, "nbformat_minor": 5}